{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "N6vmd9UIUmCl",
        "eUIqjWYEVBf3",
        "l27bEb-jVeNr",
        "uJdvqOdcjUA2",
        "WbQIj0zpkSCl",
        "j-XFl3AllS2E",
        "UOP6-WkblpVO"
      ],
      "authorship_tag": "ABX9TyN5OpPmA/8D65/c9HL79e9j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee85f27b3aa240c2b280a63826aa3104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_329d64ebc0d1470c92bd029d4ea979af",
              "IPY_MODEL_4d88b4b249604741ba2d527af186f0d3",
              "IPY_MODEL_2ae826b77cde4ad1b6f496404e59964e"
            ],
            "layout": "IPY_MODEL_f3cc9f8bc73c4a5ea4c344802c170d6b"
          }
        },
        "329d64ebc0d1470c92bd029d4ea979af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59f7bf2888449ce9b206ee4229a2c2a",
            "placeholder": "​",
            "style": "IPY_MODEL_4ad516d877a84131b211f75279d6d47f",
            "value": "config.json: 100%"
          }
        },
        "4d88b4b249604741ba2d527af186f0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e9b7650bab4fc5baad2217f85a13fe",
            "max": 1055,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f4a3b5e8bca4123a6266da580b6729f",
            "value": 1055
          }
        },
        "2ae826b77cde4ad1b6f496404e59964e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b18557c70b6f44a88533432a83225155",
            "placeholder": "​",
            "style": "IPY_MODEL_f91cbc9f041142cbbfc9f6b3c94d4a2c",
            "value": " 1.05k/1.05k [00:00&lt;00:00, 42.2kB/s]"
          }
        },
        "f3cc9f8bc73c4a5ea4c344802c170d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59f7bf2888449ce9b206ee4229a2c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad516d877a84131b211f75279d6d47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9e9b7650bab4fc5baad2217f85a13fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4a3b5e8bca4123a6266da580b6729f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b18557c70b6f44a88533432a83225155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f91cbc9f041142cbbfc9f6b3c94d4a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f3b925fc186411486ad8eb40d2334bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5fb45f7c67e41b68787fdde272eda69",
              "IPY_MODEL_778828cdc2874d5ca69f04688f5bab02",
              "IPY_MODEL_7f4f4ee78d51460a9cc9dddc0a442fa8"
            ],
            "layout": "IPY_MODEL_01493661c5914dabad22e20f52980da7"
          }
        },
        "d5fb45f7c67e41b68787fdde272eda69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35105eae342e44c69217f111bec37558",
            "placeholder": "​",
            "style": "IPY_MODEL_ee4ba88264fc4cadb730c5ca88884ead",
            "value": "model.safetensors: 100%"
          }
        },
        "778828cdc2874d5ca69f04688f5bab02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_271dca33e15b4d92bb68899740d63f87",
            "max": 4125687906,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20515ee6a9024a58bf270b822a3ade21",
            "value": 4125687906
          }
        },
        "7f4f4ee78d51460a9cc9dddc0a442fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac403d6b62584a3ba95d8430feeb0a3e",
            "placeholder": "​",
            "style": "IPY_MODEL_0dc05331042e463588153f80c82f8a09",
            "value": " 4.13G/4.13G [00:40&lt;00:00, 196MB/s]"
          }
        },
        "01493661c5914dabad22e20f52980da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35105eae342e44c69217f111bec37558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee4ba88264fc4cadb730c5ca88884ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "271dca33e15b4d92bb68899740d63f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20515ee6a9024a58bf270b822a3ade21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac403d6b62584a3ba95d8430feeb0a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dc05331042e463588153f80c82f8a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b227075839a0466aad8544cd1cbb6aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80f2686bcb8c4ec8a4ea154f90415595",
              "IPY_MODEL_5978b58f8876432b8863f5f2e35b4d43",
              "IPY_MODEL_86d848a7b4bd43f390cdbb872e42ad88"
            ],
            "layout": "IPY_MODEL_49b2c1d2d52746ccb15ba35c7a40bf25"
          }
        },
        "80f2686bcb8c4ec8a4ea154f90415595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11cd3a328a024c8a8de048d6d42465db",
            "placeholder": "​",
            "style": "IPY_MODEL_cddae495008543f58e1904af70f985b0",
            "value": "generation_config.json: 100%"
          }
        },
        "5978b58f8876432b8863f5f2e35b4d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d42cacc09da46a5a6cdf17eaf4b9bfb",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d0ef36f51434fa09903b05a717dc92c",
            "value": 116
          }
        },
        "86d848a7b4bd43f390cdbb872e42ad88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_046bc73cf9b4460a8f3d1afe9cf7dd04",
            "placeholder": "​",
            "style": "IPY_MODEL_6f45347583ed496f95577a5a2a045adc",
            "value": " 116/116 [00:00&lt;00:00, 9.32kB/s]"
          }
        },
        "49b2c1d2d52746ccb15ba35c7a40bf25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11cd3a328a024c8a8de048d6d42465db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cddae495008543f58e1904af70f985b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d42cacc09da46a5a6cdf17eaf4b9bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0ef36f51434fa09903b05a717dc92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "046bc73cf9b4460a8f3d1afe9cf7dd04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f45347583ed496f95577a5a2a045adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9770e674657540b39e8393b5bb237481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd85ce95774743c6acb2fb12f49ee8bc",
              "IPY_MODEL_2b397a6f10d5493fb0d916b865bd9283",
              "IPY_MODEL_16389003de464134a70dfb2455229f79"
            ],
            "layout": "IPY_MODEL_a04460f4729f480f8374b6e23dd2bcf8"
          }
        },
        "dd85ce95774743c6acb2fb12f49ee8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e9b075646b34e86bd0fec67956e5de2",
            "placeholder": "​",
            "style": "IPY_MODEL_1ad9573809b24d2b92afcc40024ab711",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2b397a6f10d5493fb0d916b865bd9283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_961702c3184043bfa4907cc7d6b3313f",
            "max": 971,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_136bb77a4fb34e05924d3b760f3dd444",
            "value": 971
          }
        },
        "16389003de464134a70dfb2455229f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32416814f5e549e58558f839a3c7c98a",
            "placeholder": "​",
            "style": "IPY_MODEL_09df18d4b5f14a02b4a666e39be27f98",
            "value": " 971/971 [00:00&lt;00:00, 38.5kB/s]"
          }
        },
        "a04460f4729f480f8374b6e23dd2bcf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e9b075646b34e86bd0fec67956e5de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad9573809b24d2b92afcc40024ab711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "961702c3184043bfa4907cc7d6b3313f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "136bb77a4fb34e05924d3b760f3dd444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32416814f5e549e58558f839a3c7c98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09df18d4b5f14a02b4a666e39be27f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41d02f5a1bb54ef0ac6119392245bcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e89719843e1e46efa874d1a6178cf477",
              "IPY_MODEL_09124964a5144256ad7181e6b401efe0",
              "IPY_MODEL_fe01f841093f40dbb864d796e5e60a4c"
            ],
            "layout": "IPY_MODEL_a36accb44e864455a0d894192e624fb2"
          }
        },
        "e89719843e1e46efa874d1a6178cf477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eab39a0a9fd44878b8373c8d219b571d",
            "placeholder": "​",
            "style": "IPY_MODEL_03c430b83b9d404d8c91218da419b23b",
            "value": "tokenizer.model: 100%"
          }
        },
        "09124964a5144256ad7181e6b401efe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cddf62097aa4417a1d584dc50598eff",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_735f6494970a45d4a2ef38540e8ea6ac",
            "value": 493443
          }
        },
        "fe01f841093f40dbb864d796e5e60a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccfacb4371144d2db7abcacaccee99ad",
            "placeholder": "​",
            "style": "IPY_MODEL_5262a56860bf4069b5ddb9b415a060cf",
            "value": " 493k/493k [00:00&lt;00:00, 2.11MB/s]"
          }
        },
        "a36accb44e864455a0d894192e624fb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eab39a0a9fd44878b8373c8d219b571d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c430b83b9d404d8c91218da419b23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cddf62097aa4417a1d584dc50598eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735f6494970a45d4a2ef38540e8ea6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccfacb4371144d2db7abcacaccee99ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5262a56860bf4069b5ddb9b415a060cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5067323ca3344923a038a552dbaecdf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e72e901b6794d0e87d1f8aa50f4c7b5",
              "IPY_MODEL_b2564a82e09d420a9967e2fd9b5163ca",
              "IPY_MODEL_ffd9ce0746da40599cdd69258be8fd75"
            ],
            "layout": "IPY_MODEL_e9739fb44998413482f587404375dd9c"
          }
        },
        "4e72e901b6794d0e87d1f8aa50f4c7b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87a259a4e0294982a8108c5d6511c3ad",
            "placeholder": "​",
            "style": "IPY_MODEL_1c0f7854862140f5867723cd3244cd70",
            "value": "tokenizer.json: 100%"
          }
        },
        "b2564a82e09d420a9967e2fd9b5163ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca9b3f59f7f0494bb59cc0e0cd7ff737",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d879c91fc2d148319960ea418ca60d34",
            "value": 1795303
          }
        },
        "ffd9ce0746da40599cdd69258be8fd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1940f1a79094180b734e013c03230c3",
            "placeholder": "​",
            "style": "IPY_MODEL_e3df8a57ce274faa83b505419f92b6e2",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 19.5MB/s]"
          }
        },
        "e9739fb44998413482f587404375dd9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a259a4e0294982a8108c5d6511c3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0f7854862140f5867723cd3244cd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca9b3f59f7f0494bb59cc0e0cd7ff737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d879c91fc2d148319960ea418ca60d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1940f1a79094180b734e013c03230c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3df8a57ce274faa83b505419f92b6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a18a019976345daa50022746b580d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b558aa3137f48a4b0fd051b4c8b604e",
              "IPY_MODEL_cd33576ae04f4e5f85f231726bf30821",
              "IPY_MODEL_bf3bc93b96c24716b1fe39023de02dfe"
            ],
            "layout": "IPY_MODEL_bb02178b88074077ab7c7d5317f11667"
          }
        },
        "2b558aa3137f48a4b0fd051b4c8b604e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1266df5f4c914d36beb2e76f418aa14f",
            "placeholder": "​",
            "style": "IPY_MODEL_05781f308b80430795c34466bf256a96",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "cd33576ae04f4e5f85f231726bf30821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f0f6580019439ba809778fdfd5f6d8",
            "max": 438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8c9ec77d41546e892c8d2795919aa8c",
            "value": 438
          }
        },
        "bf3bc93b96c24716b1fe39023de02dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b83c3d7a944232b4a13748a171223a",
            "placeholder": "​",
            "style": "IPY_MODEL_57af322a3ba947168e09ff7da4af74f2",
            "value": " 438/438 [00:00&lt;00:00, 31.0kB/s]"
          }
        },
        "bb02178b88074077ab7c7d5317f11667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1266df5f4c914d36beb2e76f418aa14f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05781f308b80430795c34466bf256a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04f0f6580019439ba809778fdfd5f6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c9ec77d41546e892c8d2795919aa8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60b83c3d7a944232b4a13748a171223a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57af322a3ba947168e09ff7da4af74f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e31251965e14543aec0e399833a83a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0be03905e5ca4185b1d972a10265aa2b",
              "IPY_MODEL_75d828789fb148d6918540e0f0cbf382",
              "IPY_MODEL_7644ea0845784b3789ff358c540194f7"
            ],
            "layout": "IPY_MODEL_f77dab04c2ad4bb2b8c5c4257da59f50"
          }
        },
        "0be03905e5ca4185b1d972a10265aa2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_424ee202847f4faf9074f292a90ae9fa",
            "placeholder": "​",
            "style": "IPY_MODEL_d48343d5a89f42bfb04366c3f06e41ce",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "75d828789fb148d6918540e0f0cbf382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ef058bb92942e2b59dc89ab285b5c9",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecd2a2ee252c4f908aea4432dcca889d",
            "value": 24
          }
        },
        "7644ea0845784b3789ff358c540194f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68fa6677094946399acfdaa55aac7f6c",
            "placeholder": "​",
            "style": "IPY_MODEL_faa49b7753e545dfb9e469a7b64af641",
            "value": " 24/24 [00:01&lt;00:00, 27.45 examples/s]"
          }
        },
        "f77dab04c2ad4bb2b8c5c4257da59f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "424ee202847f4faf9074f292a90ae9fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d48343d5a89f42bfb04366c3f06e41ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ef058bb92942e2b59dc89ab285b5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd2a2ee252c4f908aea4432dcca889d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68fa6677094946399acfdaa55aac7f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa49b7753e545dfb9e469a7b64af641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfEngel/OpenTuneWeaver/blob/main/OpenTuneWeaver_lite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning eines LLM\n",
        "\n",
        "Mithilfe dieses Colab-Notebooks kann man mit wenigen Schritten ein kleines Sprachmodell auf eigene Anweisungen feinabstimmen. Dafür sind ein paar Vorarbeiten wichtig. Daher bitte Schritt für Schritt dieses Notebook durchgehen und wenn erforderlich Anpassungen vornehmen.\n",
        "\n",
        "Diese Anleitung funktioniert vollständig in der freien colab-Version. Bitte beachten: Für die Laufzeit muss eine GPU gewählt werden. In der freien Version wäre das die T4 NVIDIA GPU. Diese auswählen und starten....\n",
        "\n",
        "Viel Erfolg!"
      ],
      "metadata": {
        "id": "aNEfvHDNTUIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Vorbereiten des Q&A-Datensatzes\n",
        "1.   Mit T4-GPU (mindestens) eine Laufzeit starten.\n",
        "2.   Nun das Dokument für das Finetuning wie folgt hochladen: **data.pdf**"
      ],
      "metadata": {
        "id": "8LkfS6aihAT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Einrichtung der Arbeitsumgebung und Start des Ollama-Servers\n",
        "Dieser Codeblock ist dafür zuständig, die Arbeitsumgebung für die Verwendung der Ollama KI-API vorzubereiten und den Ollama-Server zu starten. Hier eine kurze Erklärung der Schritte:\n",
        "\n",
        "* Installation notwendiger Pakete: Zuerst werden einige Linux-Pakete mit apt-get install und das Python-Paket PyPDF2 installiert. PyPDF2 ist eine Bibliothek zur Arbeit mit PDF-Dateien in Python. Das Installieren dieser Pakete ermöglicht die Nutzung von spezifischer Software und Bibliotheken, die für die folgenden Schritte benötigt werden.\n",
        "\n",
        "* Herunterladen und Einrichten von Ollama: Mit dem Befehl curl wird ein Skript von der Ollama-Webseite heruntergeladen und ausgeführt, das für die Installation und Einrichtung der Ollama KI-API sorgt. Dies ermöglicht die Verwendung der Ollama-KI-Funktionalitäten direkt im Notebook.\n",
        "\n",
        "* Starten des Ollama-Servers: Durch die Definition und Ausführung der ollama-Funktion in einem separaten Thread wird der Ollama-Server gestartet. Dieser Server ermöglicht es, Anfragen an die Ollama KI-API zu senden und Antworten zu erhalten. Die Umgebungsvariablen OLLAMA_HOST und OLLAMA_ORIGINS werden gesetzt, um den Server zu konfigurieren.\n",
        "\n",
        "* Herunterladen von KI-Modellen: Der Befehl ollama pull mistral lädt das KI-Modell „mistral“ herunter, das für die Verarbeitung der Anfragen verwendet wird. Die auskommentierten Zeilen zeigen, wie man weitere Modelle herunterladen könnte, diese sind jedoch in diesem Beispiel nicht aktiviert.\n",
        "\n",
        "Insgesamt bereitet dieser Codeblock alles Nötige vor, um den Ollama-Server zu starten und Anfragen an die Ollama KI-API zu senden. Dies ermöglicht es, fortgeschrittene KI-Funktionalitäten wie Textanalyse oder Frage-Antwort-Systeme direkt im Notebook zu nutzen."
      ],
      "metadata": {
        "id": "N6vmd9UIUmCl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tkKzx-_sjcDF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! sudo apt-get install -y pciutils\n",
        "!pip install pypdf2\n",
        "! curl https://ollama.ai/install.sh | sh\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()\n",
        "\n",
        "! ollama pull mistral\n",
        "#! ollama pull mixtral\n",
        "#! ollama pull llama2:13b\n",
        "\n",
        "#ollama_thread = threading.Thread(target=ollama)\n",
        "#ollama_thread.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Test der KI-Anfrage mit Ollama\n",
        "Dieser Codeblock führt einen Test durch, um zu überprüfen, ob die Einrichtung erfolgreich war und der Ollama-Server richtig funktioniert. Er sendet eine spezifische Frage an die KI und zeigt die Antwort an. Hier sind die Schlüsselschritte erklärt:\n",
        "\n",
        "\n",
        "*   Definieren der Anfrage: Es wird ein Text (prompt) definiert, der die Frage enthält, welche die KI beantworten soll. In diesem Fall geht es um eine kurze Erklärung zum Klimawandel. Dieser Text wird an die KI gesendet, um zu sehen, wie sie komplexe Fragen in einer einfachen und verständlichen Form beantwortet.\n",
        "\n",
        "*  Vorbereitung der Anfrage: Die Anfrage wird als payload vorbereitet, das die Details zur Anfrage, wie das zu verwendende KI-Modell (mixtral), die Temperatur für die Antwortgenerierung (0.6), und die Nachrichten enthält, die den Rahmen für die KI-Antwort setzen. Hier wird die KI als \"hilfreicher KI-Assistent\" angesprochen, um den Kontext für die Antwort zu geben.\n",
        "\n",
        "*  Senden der Anfrage: Die Anfrage wird mithilfe der requests.post-Funktion an die Ollama-API gesendet. Die API-Adresse (url) verweist auf den lokal gestarteten Ollama-Server.\n",
        "\n",
        "*  Anzeigen der Antwort: Nach dem Empfang der Antwort vom Server wird diese von einem Byte-String in ein JSON-Objekt umgewandelt (json.loads). Die Antwort der KI auf die gestellte Frage wird dann auf der Konsole ausgegeben.\n",
        "\n",
        "Dieser Test ist ein wichtiger Schritt, um sicherzustellen, dass alles korrekt eingerichtet ist und die KI wie erwartet auf Anfragen reagiert. Es hilft dabei, eventuelle Probleme in der Einrichtung oder Kommunikation mit dem Ollama-Server frühzeitig zu erkennen und zu beheben."
      ],
      "metadata": {
        "id": "eUIqjWYEVBf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Was bedeutet der Klimawandel?\n",
        "Kannst Du das in drei Sätzen erklären!\n",
        "\"\"\"\n",
        "\n",
        "url = 'http://localhost:11434/api/chat'\n",
        "payload = {\n",
        "    \"model\": \"mistral\",\n",
        "    \"temperature\": 0.6,\n",
        "    \"stream\": False,\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"Du bist ein hilfreicher KI-Assistent!\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload)\n",
        "message_str = response.content.decode('utf-8')\n",
        "message_dict = json.loads(message_str)\n",
        "print(message_dict['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trqG-h_uj-eZ",
        "outputId": "1dffa4ca-8d17-4c1a-8e15-3d78ec6f2ce7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ich glaube, dass der Begriff \"Klimawandel\" für folgende drei Sätze beschrieben werden kann:\n",
            "1. Der Klimawandel bezieht sich auf die langfristigen Änderungen in der Erdатtemperatur und der Verteilung der Temperatur und Wettermuster über die Erde.\n",
            "2. Der Hauptanteil an diesen Änderungen wird durch den menschlichen Einfluss, insbesondere durch Treibhausgas-Emissionen aus der Verbrennung von Kohle, Öl und Gas, verursacht.\n",
            "3. Die Folgen des Klimawandels sind vielfältig und umfassen Erderwärmung, Extremschwereereignisse wie Hurrikane und Dürreepisoden sowie negativ auswirksame Effekte auf das Meeresspiegel, die Landwirtschaft und die Gesundheit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Vorbereitung und Analyse eines PDF-Dokuments für Feinabstimmung\n",
        "Dieser Codeblock leitet einen Prozess zur Vorbereitung eines PDF-Dokuments für die Feinabstimmung mit einer KI ein, indem er Fragen und Antworten basierend auf dem Inhalt des Dokuments generiert. Der Prozess ist in mehrere Schlüsselschritte unterteilt:\n",
        "\n",
        "*   Text aus PDF extrahieren: Zunächst wird der Text aus der hochgeladenen PDF-Datei (data.pdf) extrahiert. Benutzer sollten darauf achten, eine PDF mit dem Namen data.pdf hochzuladen. Der Text wird dann für die weitere Verarbeitung gespeichert.\n",
        "\n",
        "*   Text in Abschnitte unterteilen: Um die Bearbeitung zu vereinfachen und die Belastung für die KI zu reduzieren, wird der Text in kleinere Abschnitte unterteilt. Diese Aufteilung hilft, den Text besser handhabbar zu machen und optimiert den Prozess der Frage-Antwort-Erzeugung.\n",
        "\n",
        "*   Frage-Antwort-Paare erzeugen: Für jeden Textabschnitt werden spezifische Frage-Antwort-Paare generiert. Dies geschieht durch das Senden des Textes an die Ollama KI-API, die instruiert wird, präzise und relevante Fragen und Antworten basierend auf dem Textinhalt zu formulieren.\n",
        "\n",
        "*   Ausgabe der aktuellen Q&A: Während des Prozesses wird jede generierte Frage-Antwort-Paarung ausgegeben. Dies ermöglicht eine sofortige Überprüfung und gewährleistet, dass die Ergebnisse wie erwartet sind. Es bietet auch die Möglichkeit, den Fortschritt zu verfolgen.\n",
        "\n",
        "*   Speichern der Ergebnisse: Am Ende werden alle generierten Frage-Antwort-Paare in einer Datei (data_qa.json) gespeichert. Diese Datei kann heruntergeladen, überarbeitet und für die Feinabstimmung der KI oder andere Zwecke verwendet werden.\n",
        "\n",
        "Dieser Prozess ist besonders nützlich für Anwender, die ihre KI-Modelle mit spezifischem Wissen aus Dokumenten anreichern oder trainieren möchten. Die generierten Q&A-Paare dienen als Basis für das Feintuning, wodurch die KI in der Lage ist, auf ähnliche Fragen in Zukunft genauer und kontextbezogener zu antworten."
      ],
      "metadata": {
        "id": "l27bEb-jVeNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import json\n",
        "import requests\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    pdf_file_obj = open(file_path, 'rb')\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file_obj)\n",
        "    text = ''\n",
        "    for page_num in range(len(pdf_reader.pages)):\n",
        "        page_obj = pdf_reader.pages[page_num]\n",
        "        text += page_obj.extract_text()\n",
        "    pdf_file_obj.close()\n",
        "    return text\n",
        "\n",
        "def split_text_into_chunks(text, chunk_size=512):\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def submit_to_ollama_api(prompt, retries=3):\n",
        "    url = 'http://localhost:11434/api/chat'\n",
        "    detailed_instruction = (\n",
        "        \"Basierend auf dem folgenden Text, formuliere bitte klare und präzise Frage-Antwort-Paare. \"\n",
        "        \"Die Fragen sollten mit 'Im Kontext ...' beginnen, um den Bezug zum Text deutlich zu machen. \"\n",
        "        \"Antworten sollten direkt aus dem Text abgeleitet und wortwörtlich übernommen werden. \"\n",
        "        \"Ziel ist es, die Informationen im Text durch diese Q&A zugänglich zu machen. \"\n",
        "        \"Hier ist ein Beispiel, wie deine Antworten aussehen sollten:\\n\\n\"\n",
        "        \"Frage: Im Kontext von Wirtschaft, was versteht man unter einem Unternehmen?\\n\"\n",
        "        \"Antwort: Ein Unternehmen ist eine Organisation oder ein Geschäft, das kommerzielle, industrielle oder professionelle Aktivitäten ausführt, um Waren zu produzieren oder Dienstleistungen gegen Gewinn anzubieten.\\n\"\n",
        "    )\n",
        "    payload = {\n",
        "        \"model\": \"mistral\",\n",
        "        \"temperature\": 0.5,\n",
        "        \"stream\": False,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": detailed_instruction},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    }\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            response = requests.post(url, json=payload)\n",
        "            if response.status_code == 200:\n",
        "                message_str = response.content.decode('utf-8')\n",
        "                message_dict = json.loads(message_str)\n",
        "                if 'content' in message_dict.get('message', {}):\n",
        "                    print(\"Aktuelle Q&A:\")\n",
        "                    print(message_dict['message']['content'])\n",
        "                    print(\"-\" * 80)  # Eine Trennlinie für bessere Lesbarkeit\n",
        "                    return message_dict['message']['content']\n",
        "                else:\n",
        "                    print(\"No valid content found in the response.\")\n",
        "            else:\n",
        "                print(f\"Attempt {i + 1} failed with status code {response.status_code}. Retrying...\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed: {e}\")\n",
        "    print(\"Max retries exceeded. Skipping this prompt.\")\n",
        "    return None\n",
        "\n",
        "text = extract_text_from_pdf('data.pdf')\n",
        "chunks = split_text_into_chunks(text, 512)\n",
        "\n",
        "responses = []\n",
        "for chunk in chunks:\n",
        "    response = submit_to_ollama_api(chunk)\n",
        "    if response:\n",
        "        responses.append(response)\n",
        "        print(\"Aktuelle Q&A:\")\n",
        "        print(response)\n",
        "        print(\"-\" * 80)  # Eine Trennlinie für bessere Lesbarkeit\n",
        "\n",
        "# Optional: Speichern der Antworten in einer Datei oder weitere Verarbeitung\n",
        "with open('data_qa.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(responses, f, ensure_ascii=False, indent=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnTHkrE2OwqU",
        "outputId": "a710ff47-75ff-4f29-fca1-b896d714aff6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Kapitels 9.1, was bezeichnen Phänomene üblicherweise?\n",
            "Antwort: Phänomene stellen typische Verhaltenseffekte dar.\n",
            "\n",
            "Frage: Im Kontexte der Beschreibung in Kapitel 4.2 und 9.1, wer sind Kahneman, Tversky, Thaler und Sunstein?\n",
            "Antwort: Kahneman, Tversky, Thaler und Sunstein sind Forscher, deren Beobachtungen zu allgemeinem Lehrgut für Entscheidungspsychologie gestellt haben.\n",
            "\n",
            "Frage: Im Kontext von Kapitel 9.1, wie beschrieben diese Zusammenfassung?\n",
            "Antswer: Diese Zusammenfassung geht zurück auf Beobachtungen von Kahneman, Tversky, Thaler und Sunstein.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Kapitels 9.1, was bezeichnen Phänomene üblicherweise?\n",
            "Antwort: Phänomene stellen typische Verhaltenseffekte dar.\n",
            "\n",
            "Frage: Im Kontexte der Beschreibung in Kapitel 4.2 und 9.1, wer sind Kahneman, Tversky, Thaler und Sunstein?\n",
            "Antwort: Kahneman, Tversky, Thaler und Sunstein sind Forscher, deren Beobachtungen zu allgemeinem Lehrgut für Entscheidungspsychologie gestellt haben.\n",
            "\n",
            "Frage: Im Kontext von Kapitel 9.1, wie beschrieben diese Zusammenfassung?\n",
            "Antswer: Diese Zusammenfassung geht zurück auf Beobachtungen von Kahneman, Tversky, Thaler und Sunstein.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Buchtitels \"Psychologie für Anfänger\", welche beiden Phänomen im Kapitel Placebo- und Nocebo-Effekt beschrieben?\n",
            "Answer: Der Placebo-Effekt beschreibt die Wirkung von Tabletten ohne Wirkstoff, basierend auf dem Glauben des Patienten. Der Nocebo-Effekt beinhaltet die Erwartung des Patienten an schädliche Nebenwirkungen des Wirkstoffs, die tatsächlich auftreten.\n",
            "\n",
            "Frage: Im Kontext des Textes, in welchem Zusammenhang wird der Name Barbara Streisand genannt?\n",
            "Answer: Der Streisand-Effekt ist benannt nach Barbara Streisand, da dieses Phänomen auftrat, als sie gegen einen Fotograf ursprünglich wegen Verletzung ihrer Privatsphäre verklagte. Folge eines hohen Medieninteresses war es, dass mehr Fotos ihres Hauses und Umfelds veröffentlicht wurden als vor dem Rechtsstreit.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Buchtitels \"Psychologie für Anfänger\", welche beiden Phänomen im Kapitel Placebo- und Nocebo-Effekt beschrieben?\n",
            "Answer: Der Placebo-Effekt beschreibt die Wirkung von Tabletten ohne Wirkstoff, basierend auf dem Glauben des Patienten. Der Nocebo-Effekt beinhaltet die Erwartung des Patienten an schädliche Nebenwirkungen des Wirkstoffs, die tatsächlich auftreten.\n",
            "\n",
            "Frage: Im Kontext des Textes, in welchem Zusammenhang wird der Name Barbara Streisand genannt?\n",
            "Answer: Der Streisand-Effekt ist benannt nach Barbara Streisand, da dieses Phänomen auftrat, als sie gegen einen Fotograf ursprünglich wegen Verletzung ihrer Privatsphäre verklagte. Folge eines hohen Medieninteresses war es, dass mehr Fotos ihres Hauses und Umfelds veröffentlicht wurden als vor dem Rechtsstreit.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des textlicher Beschreibung, was ist der Bystander-Effekt?\n",
            "Antwort: Der Bystander-Effekt beschreibt das Phänomen, dass die Hilfeleistung von Menschen in öffentlichen Situationen mit zunehmender Anwesenheit anderer Menschen abnimmt.\n",
            "\n",
            "Frage: Im Kontext des Texts, was ist der Ringelmann-Effekt?\n",
            "Antwort: Der Ringelmann-Effekt ist das Phänomen, dass in Gruppenarbeiten ein Motivationsverlust einzelner Personen entsteht, sodass die Gesamtleistung niedriger wäre, als wenn sie alleine gearbeitet hätten.\n",
            "\n",
            "Frage: Im Kontext der Beschreibung im Text, was ist der Zero-Price-Effekt?\n",
            "Antwort: Der Zero-Price-Effect geht zurück auf Lockvogel-Angebote und das Sparen von Kosten wie z.B. die Portogebühr beim Online-Einkauf über 25 Euro.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des textlicher Beschreibung, was ist der Bystander-Effekt?\n",
            "Antwort: Der Bystander-Effekt beschreibt das Phänomen, dass die Hilfeleistung von Menschen in öffentlichen Situationen mit zunehmender Anwesenheit anderer Menschen abnimmt.\n",
            "\n",
            "Frage: Im Kontext des Texts, was ist der Ringelmann-Effekt?\n",
            "Antwort: Der Ringelmann-Effekt ist das Phänomen, dass in Gruppenarbeiten ein Motivationsverlust einzelner Personen entsteht, sodass die Gesamtleistung niedriger wäre, als wenn sie alleine gearbeitet hätten.\n",
            "\n",
            "Frage: Im Kontext der Beschreibung im Text, was ist der Zero-Price-Effekt?\n",
            "Antwort: Der Zero-Price-Effect geht zurück auf Lockvogel-Angebote und das Sparen von Kosten wie z.B. die Portogebühr beim Online-Einkauf über 25 Euro.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des \"und-Julia-Effekt,\" was verbotenes Gut meist begehrt werden?\n",
            "Answer: The forbidden good is typically that which is most desired.\n",
            "\n",
            "Frage: Im Kontext des \"und-Julia-Effect,\" in what contexts are romantic fantasies idealized?\n",
            "Answer: Romantic fantasies are idealized when they never have to face the reality and everyday life.\n",
            "\n",
            "Frage: Im Kontext des \"Halo-Effekt,\" what are dominant characteristics of certain people, groups or objects associated with?\n",
            "Answer: Dominant characteristics of certain people, groups or objects are often associated with other positive attributes. For example, adipose (overweight) persons may be assoziiert with further characteristics like laziness, stupidity etc.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des \"und-Julia-Effekt,\" was verbotenes Gut meist begehrt werden?\n",
            "Answer: The forbidden good is typically that which is most desired.\n",
            "\n",
            "Frage: Im Kontext des \"und-Julia-Effect,\" in what contexts are romantic fantasies idealized?\n",
            "Answer: Romantic fantasies are idealized when they never have to face the reality and everyday life.\n",
            "\n",
            "Frage: Im Kontext des \"Halo-Effekt,\" what are dominant characteristics of certain people, groups or objects associated with?\n",
            "Answer: Dominant characteristics of certain people, groups or objects are often associated with other positive attributes. For example, adipose (overweight) persons may be assoziiert with further characteristics like laziness, stupidity etc.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der \"Aha-Effekt\" oder \"Heureka-Erlebnis\"?\n",
            "Answer: It is a psychological phenomenon where an understanding or realization of something comes suddenly after a long period of contemplation.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der \"Verknappungseffekt\"?\n",
            "Answer: It is a psychological effect that encourages the decision maker to use an automatic system and buy more than originally intended without further deliberation. This strategy is commonly used in sales and marketing.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der \"Aha-Effekt\" oder \"Heureka-Erlebnis\"?\n",
            "Answer: It is a psychological phenomenon where an understanding or realization of something comes suddenly after a long period of contemplation.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der \"Verknappungseffekt\"?\n",
            "Answer: It is a psychological effect that encourages the decision maker to use an automatic system and buy more than originally intended without further deliberation. This strategy is commonly used in sales and marketing.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Im Kontext der Psychologie, was ist der Barnum-Effekt und wie beschreibt er Reaktionen des Menschen?\n",
            "Answer: The Barnum Effect is a psychological phenomenon where people accept vague or general statements as being specifically applicable to themselves.\n",
            "\n",
            "Im Kontext der Psychologie, was bezeichnet der Valins-Effekt und in welchem Zusammenhang beschreibt er Reaktionen des Körpers?\n",
            "Answer: The Valins Effect is a psychological phenomenon where the body reacts with an increase in heart rate when observing an image.\n",
            "\n",
            "Im Kontext der Marketingpsychologie, was ist gemeint unter \"limited editions\" und wie soll der Kunde sich davon im Sinne eines vermeintlichen Gewinners gefühlen?\n",
            "Answer: In marketing context, \"limited editions\" refer to items that are produced in limited quantities. The customer may feel like a winner due to the exclusivity and perceived value of owning such an item.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Im Kontext der Psychologie, was ist der Barnum-Effekt und wie beschreibt er Reaktionen des Menschen?\n",
            "Answer: The Barnum Effect is a psychological phenomenon where people accept vague or general statements as being specifically applicable to themselves.\n",
            "\n",
            "Im Kontext der Psychologie, was bezeichnet der Valins-Effekt und in welchem Zusammenhang beschreibt er Reaktionen des Körpers?\n",
            "Answer: The Valins Effect is a psychological phenomenon where the body reacts with an increase in heart rate when observing an image.\n",
            "\n",
            "Im Kontext der Marketingpsychologie, was ist gemeint unter \"limited editions\" und wie soll der Kunde sich davon im Sinne eines vermeintlichen Gewinners gefühlen?\n",
            "Answer: In marketing context, \"limited editions\" refer to items that are produced in limited quantities. The customer may feel like a winner due to the exclusivity and perceived value of owning such an item.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der Reaktanz-Effekt und in welchem Zusammenhang wird er beschrieben?\n",
            "Answer: Der Reaktanz-EFFekt ist ein psychologischer Phänomen, bei dem Personen ihre alten Verhaltensweisen heimlich fortführen, auch wenn sie verboten sind.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Zeigarnik-Effekt oder Cliffhanger und wie sind die offenen Aufgaben im Zusammenhang mit diesem Effekt?\n",
            "Answer: Der Zeigarnik-EFFekt bzw. Cliffhanger ist ein psychologischer Phänomen, bei dem unvollständige oder offene Aufgaben unsere Aufmerksamkeit und Energie besonders stark anziehen. Dieser Effekt beruht auf der Tatsache, dass offene Aufgaben unvollständig bleiben und uns damit unruhig machen.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der Reaktanz-Effekt und in welchem Zusammenhang wird er beschrieben?\n",
            "Answer: Der Reaktanz-EFFekt ist ein psychologischer Phänomen, bei dem Personen ihre alten Verhaltensweisen heimlich fortführen, auch wenn sie verboten sind.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Zeigarnik-Effekt oder Cliffhanger und wie sind die offenen Aufgaben im Zusammenhang mit diesem Effekt?\n",
            "Answer: Der Zeigarnik-EFFekt bzw. Cliffhanger ist ein psychologischer Phänomen, bei dem unvollständige oder offene Aufgaben unsere Aufmerksamkeit und Energie besonders stark anziehen. Dieser Effekt beruht auf der Tatsache, dass offene Aufgaben unvollständig bleiben und uns damit unruhig machen.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, welche beiden Effekte auf Leistungssteigerung bei intelligenter Personengruppe werden erwähnt?\n",
            "Answer: Der Icheffekt oder Big-Fish-Little-Pond-Effect und der Rezenz-Effekt oder Primäreffekt.\n",
            "\n",
            "Frage: Im Kontext des Textes, in welchem Kapitel ist der Primacy-Recency-Effekt beschrieben?\n",
            "Answer: Der Primary-Recency-Effekt wird im Kapitel 4.4 beschrieben.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, welche beiden Effekte auf Leistungssteigerung bei intelligenter Personengruppe werden erwähnt?\n",
            "Answer: Der Icheffekt oder Big-Fish-Little-Pond-Effect und der Rezenz-Effekt oder Primäreffekt.\n",
            "\n",
            "Frage: Im Kontext des Textes, in welchem Kapitel ist der Primacy-Recency-Effekt beschrieben?\n",
            "Answer: Der Primary-Recency-Effekt wird im Kapitel 4.4 beschrieben.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Rajkov-Effekt, in welcher Zustand wurden Personen versetzt, um die Wirkungen beobachten zu können?\n",
            "Answer: Personen wurden in Tiefenhypnose versetzt.\n",
            "\n",
            "Frage: Im Kontext des Rajkov-Effekt, was wurde den Personen während der Hypnose erzählt?\n",
            "Answer: Es wurde erklärt, dass sie selbst in einem früheren Dasein eine bedeutende Person waren.\n",
            "\n",
            "Frage: Im Kontext des Rajkov-Effekt, welche Fähigkeiten entwickelten einige Personen nach der Hypnose?\n",
            "Answer: Einige Personen entwickelten Fähigkeiten, die nur für die bedeutenden Persönlichkeiten möglich waren.\n",
            "\n",
            "Frage: Im Kontext des Sozialen Erleichterungseffekts oder Publikumseffektes, wie verhielt sich Menschen unter Beobachtung?\n",
            "Answer: Menschen wurden sehr aktiv und konnten teils schwerere Aufgaben besser erledigen.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Rajkov-Effekt, in welcher Zustand wurden Personen versetzt, um die Wirkungen beobachten zu können?\n",
            "Answer: Personen wurden in Tiefenhypnose versetzt.\n",
            "\n",
            "Frage: Im Kontext des Rajkov-Effekt, was wurde den Personen während der Hypnose erzählt?\n",
            "Answer: Es wurde erklärt, dass sie selbst in einem früheren Dasein eine bedeutende Person waren.\n",
            "\n",
            "Frage: Im Kontext des Rajkov-Effekt, welche Fähigkeiten entwickelten einige Personen nach der Hypnose?\n",
            "Answer: Einige Personen entwickelten Fähigkeiten, die nur für die bedeutenden Persönlichkeiten möglich waren.\n",
            "\n",
            "Frage: Im Kontext des Sozialen Erleichterungseffekts oder Publikumseffektes, wie verhielt sich Menschen unter Beobachtung?\n",
            "Answer: Menschen wurden sehr aktiv und konnten teils schwerere Aufgaben besser erledigen.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Dutch Admiral Paradigm or Reputation Effect, what is the source of its impact?\n",
            "Answer: The effect relies on mutual praise and reputations within a society.\n",
            "\n",
            "Frage: Im Kontextextra von Charisma, was verursacht den Kennedy-Effect?\n",
            "Antwort: Der Kennedy-Effect entsteht aufgrund des hohen Charisma seines Trägers.\n",
            "\n",
            "Frage: Im Kontext des Sympathieeffekts, on what factor does its effectiveness depend?\n",
            "Answer: The effect depends on the perception and reaction of a decision maker towards someone.\n",
            "\n",
            "Frage: Im Kontext von Psychology, in what way does charisma influence power and influence?\n",
            "Answer: Charisma leads to increasing power and influence through the Kennedy-Effect and Sympathy Effect.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Dutch Admiral Paradigm or Reputation Effect, what is the source of its impact?\n",
            "Answer: The effect relies on mutual praise and reputations within a society.\n",
            "\n",
            "Frage: Im Kontextextra von Charisma, was verursacht den Kennedy-Effect?\n",
            "Antwort: Der Kennedy-Effect entsteht aufgrund des hohen Charisma seines Trägers.\n",
            "\n",
            "Frage: Im Kontext des Sympathieeffekts, on what factor does its effectiveness depend?\n",
            "Answer: The effect depends on the perception and reaction of a decision maker towards someone.\n",
            "\n",
            "Frage: Im Kontext von Psychology, in what way does charisma influence power and influence?\n",
            "Answer: Charisma leads to increasing power and influence through the Kennedy-Effect and Sympathy Effect.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was bezieht der Pygmalion- oder Rosenthal-Effekt auf?\n",
            "Answer: Der Pygmalion- oder Rosenthal-Effekt ist ein Phänomen, das sich auf die Motivationsveränderung durch Erwartungen zurückführen lässt. In einem Experiment, beispielsweise mit Lehrern, die glaubten, die beste Klasse des neuen Schuljahres zu bekommen, waren tatsächlich diese Schüler am Ende des Schuljahres deutlich besser, obwohl dies nicht der Fall war.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Hawthorne-Effekt?\n",
            "Answer: Der Hawthorne-Effect (bei unvollständigem Satz: oder Beobachtungseffekt) ist ein Phänomen in der Verhaltensökonomik, bei dem die bloße Beobachtung und Aufmerksamkeit einer Gruppe eine positive Wirkung auf ihre Leistung hat.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was bezieht der Pygmalion- oder Rosenthal-Effekt auf?\n",
            "Answer: Der Pygmalion- oder Rosenthal-Effekt ist ein Phänomen, das sich auf die Motivationsveränderung durch Erwartungen zurückführen lässt. In einem Experiment, beispielsweise mit Lehrern, die glaubten, die beste Klasse des neuen Schuljahres zu bekommen, waren tatsächlich diese Schüler am Ende des Schuljahres deutlich besser, obwohl dies nicht der Fall war.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Hawthorne-Effekt?\n",
            "Answer: Der Hawthorne-Effect (bei unvollständigem Satz: oder Beobachtungseffekt) ist ein Phänomen in der Verhaltensökonomik, bei dem die bloße Beobachtung und Aufmerksamkeit einer Gruppe eine positive Wirkung auf ihre Leistung hat.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Psychologischen Phänomen, was ist der Kobraffekt?\n",
            "Answer: Der Kobraffekt bezeichnet den Zusammenhang zwischen einer negativen Vorstellung und einem positiven Ereignis, das bei der Wahrnehmung des letzteren die Negativität überlagert und zu einer schlechteren Wirkung führt.\n",
            "\n",
            "Frage: Im Kontext des Psychologischen Phänomen, was waren die Hawthorne-Werke?\n",
            "Answer: Die Hawthorne-Werke waren eine Reihe von Studien zur Arbeitsmotivation und Produktivität durch Elton Mayo am Hawthorn Works der Western Electric Company in Cicero (Illinois) zwischen 1924 und 1932.\n",
            "\n",
            "Frage: Im Kontext des Psychologischen Phänomen, welche Studien wurden in den Hawthorne-Werken durchgeführt?\n",
            "Answer: In den Hawthorne-Studien wurden verschiedene Versuche zur Erhöhung der Lichtbeschickung (lighting experiments) sowie andere Arbeitsbedingungen und Belohnungen durchgeführt, um die Produktivität der Mitarbeiter zu verbessern.\n",
            "\n",
            "Frage: Im Kontext des Psychologischen Phänomen, was ist der Achtungseffekt?\n",
            "Answer: Der Achtungseffekt bezeichnet das Auftreten einer Verbesserung von Leistungen, die durch die Aufmerksamkeit und Wahrnehmung anderer aufgebracht wird. Dieses Phänomen wurde erstmals in den Hawthorne-Studien beobachtet.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Psychologischen Phänomen, was ist der Kobraffekt?\n",
            "Answer: Der Kobraffekt bezeichnet den Zusammenhang zwischen einer negativen Vorstellung und einem positiven Ereignis, das bei der Wahrnehmung des letzteren die Negativität überlagert und zu einer schlechteren Wirkung führt.\n",
            "\n",
            "Frage: Im Kontext des Psychologischen Phänomen, was waren die Hawthorne-Werke?\n",
            "Answer: Die Hawthorne-Werke waren eine Reihe von Studien zur Arbeitsmotivation und Produktivität durch Elton Mayo am Hawthorn Works der Western Electric Company in Cicero (Illinois) zwischen 1924 und 1932.\n",
            "\n",
            "Frage: Im Kontext des Psychologischen Phänomen, welche Studien wurden in den Hawthorne-Werken durchgeführt?\n",
            "Answer: In den Hawthorne-Studien wurden verschiedene Versuche zur Erhöhung der Lichtbeschickung (lighting experiments) sowie andere Arbeitsbedingungen und Belohnungen durchgeführt, um die Produktivität der Mitarbeiter zu verbessern.\n",
            "\n",
            "Frage: Im Kontext des Psychologischen Phänomen, was ist der Achtungseffekt?\n",
            "Answer: Der Achtungseffekt bezeichnet das Auftreten einer Verbesserung von Leistungen, die durch die Aufmerksamkeit und Wahrnehmung anderer aufgebracht wird. Dieses Phänomen wurde erstmals in den Hawthorne-Studien beobachtet.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was versuchten die Kolonialherren in Indien mit Schlangen?\n",
            "Antwort: Sie versuchten, eine Schlangenplage durch ein Kopfgeld je Schlange zu bekämpfen.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Kontrasteffekt?\n",
            "Antswer: Der Kontrasteffekt beruht auf der verzerrten Wahrnehmung von kontrastaren Informationen.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Werther-Effekt?\n",
            "Answer: Der Werther-Effekt beruht auf der Nachahmung und tritt bei der Berichterstattung über Selbstmord durch Drogenkonsum auf.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was versuchten die Kolonialherren in Indien mit Schlangen?\n",
            "Antwort: Sie versuchten, eine Schlangenplage durch ein Kopfgeld je Schlange zu bekämpfen.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Kontrasteffekt?\n",
            "Antswer: Der Kontrasteffekt beruht auf der verzerrten Wahrnehmung von kontrastaren Informationen.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Werther-Effekt?\n",
            "Answer: Der Werther-Effekt beruht auf der Nachahmung und tritt bei der Berichterstattung über Selbstmord durch Drogenkonsum auf.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der Simsulationseffekt / Angleichungseffekt?\n",
            "Answer: Der Simsulationseffekt / Angleichungseffekt ist ein Phänomen, das auftritt, wenn Produkte als Ergänzung zu bevorzugt gekauft werden.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Reflected-Glory-Effekt?\n",
            "Answer: Der Reflected-Glory-Effekt ist ein Phänomen, das auftritt, wenn Produkte wie dem iPad, die nach einem erfolgreichen Vorgängerprodukt wie dem iPhone hergestellt werden, für das Unternehmen gute Umsätze eingebracht werden sollten.\n",
            "\n",
            "Frage: Im Kontext des Textes, was bedeutet der Matthäus-Effekt?\n",
            "Answer: Der Matthäus-Effekt ist ein Phänomen, das in diesem Zusammenhang mitglücklichem und peinlichem Verhalten assoziiert ist. Das Zitat aus dem Matthäus-Evangelium der Bibel belegt die These, dass Glück und Pech jeweils ansteckend sein sollen.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der Simsulationseffekt / Angleichungseffekt?\n",
            "Answer: Der Simsulationseffekt / Angleichungseffekt ist ein Phänomen, das auftritt, wenn Produkte als Ergänzung zu bevorzugt gekauft werden.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist der Reflected-Glory-Effekt?\n",
            "Answer: Der Reflected-Glory-Effekt ist ein Phänomen, das auftritt, wenn Produkte wie dem iPad, die nach einem erfolgreichen Vorgängerprodukt wie dem iPhone hergestellt werden, für das Unternehmen gute Umsätze eingebracht werden sollten.\n",
            "\n",
            "Frage: Im Kontext des Textes, was bedeutet der Matthäus-Effekt?\n",
            "Answer: Der Matthäus-Effekt ist ein Phänomen, das in diesem Zusammenhang mitglücklichem und peinlichem Verhalten assoziiert ist. Das Zitat aus dem Matthäus-Evangelium der Bibel belegt die These, dass Glück und Pech jeweils ansteckend sein sollen.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Films und der Filmtheorie, was ist der Kuleshov-Effekt?\n",
            "Answer: The Kuleshov Effect is a concept in film theory where the meaning of an image can change depending on the context created by surrounding images.\n",
            "\n",
            "Frage: Im Kontext der Filmtheorie, was ist der Veblen-Effekt oder Snob-Effect?\n",
            "Answer: The Veblen Effect or Snob Effect is a phenomenon in economics where the desire for a product increases as its price increases due to the perception of exclusivity and prestige.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Films und der Filmtheorie, was ist der Kuleshov-Effekt?\n",
            "Answer: The Kuleshov Effect is a concept in film theory where the meaning of an image can change depending on the context created by surrounding images.\n",
            "\n",
            "Frage: Im Kontext der Filmtheorie, was ist der Veblen-Effekt oder Snob-Effect?\n",
            "Answer: The Veblen Effect or Snob Effect is a phenomenon in economics where the desire for a product increases as its price increases due to the perception of exclusivity and prestige.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was führt zur steigenden Nachfrage bei Luxusgütern trotz steigender Preise?\n",
            "Answer: People willingly pay more for the exclusivity.\n",
            "\n",
            "Frage: In der Textpassage wird welcher psychologische Effekt auf Perfektion bezogen?\n",
            "Answer: The Pratfall Effect makes perfection intimidating and unapproachable, while imperfection is charming and attractive.\n",
            "\n",
            "Frage: Was ist der Ursprung des Jesaja-Effects?\n",
            "Answer: It refers to the biblical figure of Isaiah, known for his prophecies, which can be used to draw attention to current and future actions.\n",
            "\n",
            "Frage: Welcher Effekt wird im Text beschrieben, der mit dem Weihnachtseffekt assoziiert ist?\n",
            "Answer: The text discusses the Weihnachtseffect, but it is not explicitly explained what this term refers to.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was führt zur steigenden Nachfrage bei Luxusgütern trotz steigender Preise?\n",
            "Answer: People willingly pay more for the exclusivity.\n",
            "\n",
            "Frage: In der Textpassage wird welcher psychologische Effekt auf Perfektion bezogen?\n",
            "Answer: The Pratfall Effect makes perfection intimidating and unapproachable, while imperfection is charming and attractive.\n",
            "\n",
            "Frage: Was ist der Ursprung des Jesaja-Effects?\n",
            "Answer: It refers to the biblical figure of Isaiah, known for his prophecies, which can be used to draw attention to current and future actions.\n",
            "\n",
            "Frage: Welcher Effekt wird im Text beschrieben, der mit dem Weihnachtseffekt assoziiert ist?\n",
            "Answer: The text discusses the Weihnachtseffect, but it is not explicitly explained what this term refers to.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontexte des Textes, was wird unter \"Framing Effect\" verstanden?\n",
            "Answer: Der Framing Effect ist ein psychologischer Effekt, der auf die Art und Weise beeinflusst, wie Menschen Information wahrnehmen und entscheiden. Er wurde in Kapitel 4.4 erläutert. Konkret geht es um die Wirkung einer veränderten Darstellung (Framing) einer Information.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist mit \"Fernbeziehungen\" zu tun?\n",
            "Answer: Fernbeziehungen beziehen sich auf Beziehungen zwischen Menschen, die über größere Entfernungen hinweg bestehen. In diesem Text wird erwähnt, dass solche Beziehungen für die kurze Zeit des Wiedersehens planungsschwierig sein können.\n",
            "\n",
            "Frage: Im Kontext des Textes, was kann es zu Streit führen, wenn Menschen aus Fernbeziehungen planen?\n",
            "Answer: Es kann zu Streit führen, da die Planung der eine Person oft mit der Planung der anderen kollidiert.\n",
            "\n",
            "Frage: Im Kontext des Textes, was bedeutet \"sinngemäß\" im Zusammenhang des Framing Effect?\n",
            "Answer: \"Sinngemäß\" bedeutet im Sinne oder in der Bedeutung von etwas. Im Zusammenhang des Framing Effects geht es um die tiefgreifende Wirkung einer Information durch eine veränderte Darstellung (Framing).\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontexte des Textes, was wird unter \"Framing Effect\" verstanden?\n",
            "Answer: Der Framing Effect ist ein psychologischer Effekt, der auf die Art und Weise beeinflusst, wie Menschen Information wahrnehmen und entscheiden. Er wurde in Kapitel 4.4 erläutert. Konkret geht es um die Wirkung einer veränderten Darstellung (Framing) einer Information.\n",
            "\n",
            "Frage: Im Kontext des Textes, was ist mit \"Fernbeziehungen\" zu tun?\n",
            "Answer: Fernbeziehungen beziehen sich auf Beziehungen zwischen Menschen, die über größere Entfernungen hinweg bestehen. In diesem Text wird erwähnt, dass solche Beziehungen für die kurze Zeit des Wiedersehens planungsschwierig sein können.\n",
            "\n",
            "Frage: Im Kontext des Textes, was kann es zu Streit führen, wenn Menschen aus Fernbeziehungen planen?\n",
            "Answer: Es kann zu Streit führen, da die Planung der eine Person oft mit der Planung der anderen kollidiert.\n",
            "\n",
            "Frage: Im Kontext des Textes, was bedeutet \"sinngemäß\" im Zusammenhang des Framing Effect?\n",
            "Answer: \"Sinngemäß\" bedeutet im Sinne oder in der Bedeutung von etwas. Im Zusammenhang des Framing Effects geht es um die tiefgreifende Wirkung einer Information durch eine veränderte Darstellung (Framing).\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der Begründungs-Effekt?\n",
            "Answer: Der Begründungs-EFFekt ist ein psychologisches Phänomen, bei dem begründende Worte wie „weil“ starke Richtungslenker wahrgenommen und falsche Begründungen häufiger akzeptiert werden.\n",
            "\n",
            "Frage: Im Kontext des Textes, was bezeichnet der Manhattan-Effekt?\n",
            "Answer: Der Manhattan-EFFekt ist ein psychologisches Phänomen, das sich auf Beziehungen bezieht, die nicht mehr intakt sind. Dabei wird die Unterstützung des Partners nicht mehr so stark gefordert, da die Umsetzung der persönlichen Interessen des Partners als Bedrohung für die eigene Identität wahrgenommen wird.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der Begründungs-Effekt?\n",
            "Answer: Der Begründungs-EFFekt ist ein psychologisches Phänomen, bei dem begründende Worte wie „weil“ starke Richtungslenker wahrgenommen und falsche Begründungen häufiger akzeptiert werden.\n",
            "\n",
            "Frage: Im Kontext des Textes, was bezeichnet der Manhattan-Effekt?\n",
            "Answer: Der Manhattan-EFFekt ist ein psychologisches Phänomen, das sich auf Beziehungen bezieht, die nicht mehr intakt sind. Dabei wird die Unterstützung des Partners nicht mehr so stark gefordert, da die Umsetzung der persönlichen Interessen des Partners als Bedrohung für die eigene Identität wahrgenommen wird.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Sunk Costs Effect, welche Art von Kosten sind dies irreversibel?\n",
            "Antwort: Die bereits getätigten Zahlungen sind irreversibel im Sunk Costs Effect.\n",
            "\n",
            "Frage: In Kapitel 4.2.4, was wird darüber erläutert, wie irgendeine Vorauslagen in Planung zukünftiger Kosten berücksichtigt werden sollten?\n",
            "Answer: Es wird darüber im Sunk Costs Effect erläutert, dass sie nicht mitbeachtet und miteinbezogen werden sollten.\n",
            "\n",
            "Frage: Was ist der Hintergrund des Honeymoon-Effects?\n",
            "Antwort: Der Honeymoon-Effect geht auf die sexuelle Aktivität von Paaren zurück.\n",
            "\n",
            "Frage: In welchem Kapitel und Absatz wird der Honeymoon-Effect erwähnt?\n",
            "Answer: Der Honeymoon-Effect wird im Kapitel 4.2.4 erwähnt.\n",
            "\n",
            "Frage: Im Kontext von Psychologie, was ist der Honeymoon-Effect?\n",
            "Antwort: Der Honeymoon-Effect ist ein psychologischer Effekt, bei dem die sexuelle Aktivität von Paaren sehr hoch ist zu Beginn ihrer Partnerschaft.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Sunk Costs Effect, welche Art von Kosten sind dies irreversibel?\n",
            "Antwort: Die bereits getätigten Zahlungen sind irreversibel im Sunk Costs Effect.\n",
            "\n",
            "Frage: In Kapitel 4.2.4, was wird darüber erläutert, wie irgendeine Vorauslagen in Planung zukünftiger Kosten berücksichtigt werden sollten?\n",
            "Answer: Es wird darüber im Sunk Costs Effect erläutert, dass sie nicht mitbeachtet und miteinbezogen werden sollten.\n",
            "\n",
            "Frage: Was ist der Hintergrund des Honeymoon-Effects?\n",
            "Antwort: Der Honeymoon-Effect geht auf die sexuelle Aktivität von Paaren zurück.\n",
            "\n",
            "Frage: In welchem Kapitel und Absatz wird der Honeymoon-Effect erwähnt?\n",
            "Answer: Der Honeymoon-Effect wird im Kapitel 4.2.4 erwähnt.\n",
            "\n",
            "Frage: Im Kontext von Psychologie, was ist der Honeymoon-Effect?\n",
            "Antwort: Der Honeymoon-Effect ist ein psychologischer Effekt, bei dem die sexuelle Aktivität von Paaren sehr hoch ist zu Beginn ihrer Partnerschaft.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Broken-Windows-Effekts, was verursacht den initialen Zerstörung der Fenster?\n",
            "Answer: The broken windows are caused by an external event or series of events.\n",
            "\n",
            "Frage: Im Kontext des Broken-Windows-Effekts, wie wird das Zerbrechen eines Hauses Fensters auf andere Häuser in der Nachbarschaft auswirken?\n",
            "Answer: It is likely that other houses in the neighborhood will also experience broken windows.\n",
            "\n",
            "Frage: Im Kontext des Broken-Windows-Effekts, from where does the effect originate?\n",
            "Answer: The origin of the Broken-Windows Effect can be traced back to a study in the 1960s by two criminologists, Colward and Loeber.\n",
            "\n",
            "Frage: Im Kontext des Vorführ-Effekts, what are the normal functioning Abläufe being referred to?\n",
            "Answer: The normal functioning ablaufe are regular or expected events or processes.\n",
            "\n",
            "Frage: Im Kontext des Vorführ-Effekts, how does a disruption in these normal functioning ablaufe affect the outcome of an event or situation?\n",
            "Answer: A disruption in these normal functioning ablaufe can significantly impact the outcome.\n",
            "\n",
            "Frage: Im Kontext des Schreck-Effekts, what does it suggest about initial impressions when meeting a potential partner?\n",
            "Answer: The Schreck-Effect suggests that first impressions matter greatly and can influence our perceptions and behaviors.\n",
            "\n",
            "Frage: Im Kontext des Schreck-Effekts, how might this effect be observed in everyday situations?\n",
            "Answer: This effect may be observed when we encounter someone or something new for the first time, and our perception of them is negatively influenced by a single incident or impression.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Broken-Windows-Effekts, was verursacht den initialen Zerstörung der Fenster?\n",
            "Answer: The broken windows are caused by an external event or series of events.\n",
            "\n",
            "Frage: Im Kontext des Broken-Windows-Effekts, wie wird das Zerbrechen eines Hauses Fensters auf andere Häuser in der Nachbarschaft auswirken?\n",
            "Answer: It is likely that other houses in the neighborhood will also experience broken windows.\n",
            "\n",
            "Frage: Im Kontext des Broken-Windows-Effekts, from where does the effect originate?\n",
            "Answer: The origin of the Broken-Windows Effect can be traced back to a study in the 1960s by two criminologists, Colward and Loeber.\n",
            "\n",
            "Frage: Im Kontext des Vorführ-Effekts, what are the normal functioning Abläufe being referred to?\n",
            "Answer: The normal functioning ablaufe are regular or expected events or processes.\n",
            "\n",
            "Frage: Im Kontext des Vorführ-Effekts, how does a disruption in these normal functioning ablaufe affect the outcome of an event or situation?\n",
            "Answer: A disruption in these normal functioning ablaufe can significantly impact the outcome.\n",
            "\n",
            "Frage: Im Kontext des Schreck-Effekts, what does it suggest about initial impressions when meeting a potential partner?\n",
            "Answer: The Schreck-Effect suggests that first impressions matter greatly and can influence our perceptions and behaviors.\n",
            "\n",
            "Frage: Im Kontext des Schreck-Effekts, how might this effect be observed in everyday situations?\n",
            "Answer: This effect may be observed when we encounter someone or something new for the first time, and our perception of them is negatively influenced by a single incident or impression.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage 1: Im Kontext des Westermarck-Effekts, was bedeutet es, \"die Kindheit langsam verbracht zu haben\"?\n",
            "Answer 1: Es meint, dass Menschen, die seit ihrer Kindheit miteinander vertraut sind, keinerlei erotische Gefühle füreinander aufbringen werden.\n",
            "\n",
            "Frage 2: Im Kontext des Textes, was ist der Westermarck-Effekt?\n",
            "Answer 2: Der Westermarck-Effekt ist ein Phänomen, das darauf zurückgeht, dass Menschen, die seit langer Zeit miteinander vertraut sind (z.B. aus der Kindheit), keine erotischen Gefühle füreinander aufbringen werden.\n",
            "\n",
            "Frage 3: Im Kontext des Textes, was ist der McGurk-Effekt?\n",
            "Answer 3: Der McGurk-Effekt ist ein Phänomen, das darauf zurückgeht, dass Menschen unterschiedliche Reize zugleich wahrnehmen und vermischen, was dazu führt, dass sie falschen Wortlauten hören.\n",
            "\n",
            "Frage 4: Im Kontext des Textes, wie beeinflussen miteinander die männlichen und weiblichen Rollen die Spannung in der Situation?\n",
            "Answer 4: In spannenden Situationen scheinen Männer attraktiver zu wirken für Frauen, die sich in bedrohlichen Momenten eher zur vertrauten Person hingezogen fühlen.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage 1: Im Kontext des Westermarck-Effekts, was bedeutet es, \"die Kindheit langsam verbracht zu haben\"?\n",
            "Answer 1: Es meint, dass Menschen, die seit ihrer Kindheit miteinander vertraut sind, keinerlei erotische Gefühle füreinander aufbringen werden.\n",
            "\n",
            "Frage 2: Im Kontext des Textes, was ist der Westermarck-Effekt?\n",
            "Answer 2: Der Westermarck-Effekt ist ein Phänomen, das darauf zurückgeht, dass Menschen, die seit langer Zeit miteinander vertraut sind (z.B. aus der Kindheit), keine erotischen Gefühle füreinander aufbringen werden.\n",
            "\n",
            "Frage 3: Im Kontext des Textes, was ist der McGurk-Effekt?\n",
            "Answer 3: Der McGurk-Effekt ist ein Phänomen, das darauf zurückgeht, dass Menschen unterschiedliche Reize zugleich wahrnehmen und vermischen, was dazu führt, dass sie falschen Wortlauten hören.\n",
            "\n",
            "Frage 4: Im Kontext des Textes, wie beeinflussen miteinander die männlichen und weiblichen Rollen die Spannung in der Situation?\n",
            "Answer 4: In spannenden Situationen scheinen Männer attraktiver zu wirken für Frauen, die sich in bedrohlichen Momenten eher zur vertrauten Person hingezogen fühlen.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was sind die \"iedlichen Sinnesinformationen\" und wie können sie eine Wahrnehmungsstörung verursachen?\n",
            "Answer: The term \"iedliche Sinnesinformationen\" refers to sensory information such as those from the eyes, ears, nose, or mouth. These can lead to a perceptual disturbance and create false realities.\n",
            "\n",
            "Frage: In context, what is the \"Obelix-Effect\" based on?\n",
            "Answer: The Obelix-Effect refers to a phenomenon where people who are left out feel envy towards others and may create imaginary scenarios in their minds.\n",
            "\n",
            "Frage: Im Kontext des Textes, was geht der \"Obelix-EFFekt\" auf die Beobachtung von Menschen hinterher zurück?\n",
            "Answer: The Obelix-Effect is based on the observation of people feeling envy towards others who are included in certain activities or groups without being invited.\n",
            "\n",
            "Frage: In context, was der \"Luzifer-Effekt\" ursprünglich inspiriert von?\n",
            "Answer: The Luzifer-Effect is originally inspired by the Stanford Prison Experiment, where two groups of participants were randomly assigned roles as guards and prisoners, leading to power abuses among the guards and negative behavior from the prisoners.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was sind die \"iedlichen Sinnesinformationen\" und wie können sie eine Wahrnehmungsstörung verursachen?\n",
            "Answer: The term \"iedliche Sinnesinformationen\" refers to sensory information such as those from the eyes, ears, nose, or mouth. These can lead to a perceptual disturbance and create false realities.\n",
            "\n",
            "Frage: In context, what is the \"Obelix-Effect\" based on?\n",
            "Answer: The Obelix-Effect refers to a phenomenon where people who are left out feel envy towards others and may create imaginary scenarios in their minds.\n",
            "\n",
            "Frage: Im Kontext des Textes, was geht der \"Obelix-EFFekt\" auf die Beobachtung von Menschen hinterher zurück?\n",
            "Answer: The Obelix-Effect is based on the observation of people feeling envy towards others who are included in certain activities or groups without being invited.\n",
            "\n",
            "Frage: In context, was der \"Luzifer-Effekt\" ursprünglich inspiriert von?\n",
            "Answer: The Luzifer-Effect is originally inspired by the Stanford Prison Experiment, where two groups of participants were randomly assigned roles as guards and prisoners, leading to power abuses among the guards and negative behavior from the prisoners.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der Michelangelo-Effekt?\n",
            "Answer: The Michelangelo Effect states that every human being already exists in their complete ideal form and unnecessary obstacles should be removed.\n",
            "\n",
            "Frage: Im Kontext des Textes, was besagt der Rosenthal-Effekt?\n",
            "Answer: The Rosenthal Effect states that when one has a high expectation of oneself, they can indeed achieve it. However, this also works in the negative sense.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Textes, was ist der Michelangelo-Effekt?\n",
            "Answer: The Michelangelo Effect states that every human being already exists in their complete ideal form and unnecessary obstacles should be removed.\n",
            "\n",
            "Frage: Im Kontext des Textes, was besagt der Rosenthal-Effekt?\n",
            "Answer: The Rosenthal Effect states that when one has a high expectation of oneself, they can indeed achieve it. However, this also works in the negative sense.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Spotlight-Effektes, was veranlasst es Menschen, dass sie auf unangenehme Merkmale anderen Menschen zusprenken?\n",
            "Antwort: Der Spotlight-Effekt beruht darauf, dass people assume that others are focusing on their own unpleasant qualities, when in fact they often receive less attention than they think.\n",
            "\n",
            "Frage: Im Kontext des Spotlight-Effect, was ist der tatsächliche Ausgang der Menschen, wenn sie auf unangenehme Merkmale anderer Menschen aufmerksam werden?\n",
            "Answer: People often receive less attention from others when they focus on their own unpleasant qualities, contrary to what they might assume.\n",
            "--------------------------------------------------------------------------------\n",
            "Aktuelle Q&A:\n",
            " Frage: Im Kontext des Spotlight-Effektes, was veranlasst es Menschen, dass sie auf unangenehme Merkmale anderen Menschen zusprenken?\n",
            "Antwort: Der Spotlight-Effekt beruht darauf, dass people assume that others are focusing on their own unpleasant qualities, when in fact they often receive less attention than they think.\n",
            "\n",
            "Frage: Im Kontext des Spotlight-Effect, was ist der tatsächliche Ausgang der Menschen, wenn sie auf unangenehme Merkmale anderer Menschen aufmerksam werden?\n",
            "Answer: People often receive less attention from others when they focus on their own unpleasant qualities, contrary to what they might assume.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# WICHTIG!!!! Zwischenschritt\n",
        "\n",
        "1.   Q&A-Datensatz herunterladen (data_qa.json)\n",
        "2.   Datensatz überarbeiten (fehlerhafte Elemente löschen/anpassen, bereinigen)\n",
        "3.   Notebook zurücksetzen\n",
        "4.   Datensatz hochladen\n",
        "5.   Notebook neu starten. Wieder mit T4-GPU\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "x00alEtYXN8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Finetuning\n",
        "\n",
        "Das folgende Skript geht zurück auf [Unsloth](https://github.com/unslothai/unsloth). Einem aktuellen Framework um auch mit wenigen Ressourcen schnell qualitativ hochwertige Ergebnisse zu erzielen.\n",
        "\n",
        "Hier der Link zum Original-Notebook von [Mistral7b-Unsloth](https://colab.research.google.com/drive/1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_?usp=sharing)"
      ],
      "metadata": {
        "id": "S1Uow-0xWFJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Installation nötiger Bibs und Bezug des Modells\n",
        "\n",
        "\n",
        "\n",
        "*  Zunächst müssen relevante Python-Bibs bezogen werden.\n",
        "*  Das Modell Mistral-7b wird heruntergeladen und in 4bit bereitgestellt.\n",
        "*  Das Lora-Adapter-Template wird heruntergeladen um für das Finetuning trainiert zu werden.\n",
        "*  Der Datensatz wird geladen und in das passende Format übertragen"
      ],
      "metadata": {
        "id": "uJdvqOdcjUA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "# Must install separately since Colab has torch 2.2.1, which breaks packages\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "if major_version >= 8:\n",
        "    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n",
        "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
        "else:\n",
        "    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n",
        "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
        "pass"
      ],
      "metadata": {
        "id": "20EHnQv_W_37"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
        "    \"unsloth/llama-2-13b-bnb-4bit\",\n",
        "    \"unsloth/codellama-34b-bnb-4bit\",\n",
        "    \"unsloth/tinyllama-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/mistral-7b-bnb-4bit\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "ee85f27b3aa240c2b280a63826aa3104",
            "329d64ebc0d1470c92bd029d4ea979af",
            "4d88b4b249604741ba2d527af186f0d3",
            "2ae826b77cde4ad1b6f496404e59964e",
            "f3cc9f8bc73c4a5ea4c344802c170d6b",
            "b59f7bf2888449ce9b206ee4229a2c2a",
            "4ad516d877a84131b211f75279d6d47f",
            "d9e9b7650bab4fc5baad2217f85a13fe",
            "5f4a3b5e8bca4123a6266da580b6729f",
            "b18557c70b6f44a88533432a83225155",
            "f91cbc9f041142cbbfc9f6b3c94d4a2c",
            "6f3b925fc186411486ad8eb40d2334bd",
            "d5fb45f7c67e41b68787fdde272eda69",
            "778828cdc2874d5ca69f04688f5bab02",
            "7f4f4ee78d51460a9cc9dddc0a442fa8",
            "01493661c5914dabad22e20f52980da7",
            "35105eae342e44c69217f111bec37558",
            "ee4ba88264fc4cadb730c5ca88884ead",
            "271dca33e15b4d92bb68899740d63f87",
            "20515ee6a9024a58bf270b822a3ade21",
            "ac403d6b62584a3ba95d8430feeb0a3e",
            "0dc05331042e463588153f80c82f8a09",
            "b227075839a0466aad8544cd1cbb6aff",
            "80f2686bcb8c4ec8a4ea154f90415595",
            "5978b58f8876432b8863f5f2e35b4d43",
            "86d848a7b4bd43f390cdbb872e42ad88",
            "49b2c1d2d52746ccb15ba35c7a40bf25",
            "11cd3a328a024c8a8de048d6d42465db",
            "cddae495008543f58e1904af70f985b0",
            "0d42cacc09da46a5a6cdf17eaf4b9bfb",
            "8d0ef36f51434fa09903b05a717dc92c",
            "046bc73cf9b4460a8f3d1afe9cf7dd04",
            "6f45347583ed496f95577a5a2a045adc",
            "9770e674657540b39e8393b5bb237481",
            "dd85ce95774743c6acb2fb12f49ee8bc",
            "2b397a6f10d5493fb0d916b865bd9283",
            "16389003de464134a70dfb2455229f79",
            "a04460f4729f480f8374b6e23dd2bcf8",
            "6e9b075646b34e86bd0fec67956e5de2",
            "1ad9573809b24d2b92afcc40024ab711",
            "961702c3184043bfa4907cc7d6b3313f",
            "136bb77a4fb34e05924d3b760f3dd444",
            "32416814f5e549e58558f839a3c7c98a",
            "09df18d4b5f14a02b4a666e39be27f98",
            "41d02f5a1bb54ef0ac6119392245bcf1",
            "e89719843e1e46efa874d1a6178cf477",
            "09124964a5144256ad7181e6b401efe0",
            "fe01f841093f40dbb864d796e5e60a4c",
            "a36accb44e864455a0d894192e624fb2",
            "eab39a0a9fd44878b8373c8d219b571d",
            "03c430b83b9d404d8c91218da419b23b",
            "2cddf62097aa4417a1d584dc50598eff",
            "735f6494970a45d4a2ef38540e8ea6ac",
            "ccfacb4371144d2db7abcacaccee99ad",
            "5262a56860bf4069b5ddb9b415a060cf",
            "5067323ca3344923a038a552dbaecdf4",
            "4e72e901b6794d0e87d1f8aa50f4c7b5",
            "b2564a82e09d420a9967e2fd9b5163ca",
            "ffd9ce0746da40599cdd69258be8fd75",
            "e9739fb44998413482f587404375dd9c",
            "87a259a4e0294982a8108c5d6511c3ad",
            "1c0f7854862140f5867723cd3244cd70",
            "ca9b3f59f7f0494bb59cc0e0cd7ff737",
            "d879c91fc2d148319960ea418ca60d34",
            "f1940f1a79094180b734e013c03230c3",
            "e3df8a57ce274faa83b505419f92b6e2",
            "1a18a019976345daa50022746b580d62",
            "2b558aa3137f48a4b0fd051b4c8b604e",
            "cd33576ae04f4e5f85f231726bf30821",
            "bf3bc93b96c24716b1fe39023de02dfe",
            "bb02178b88074077ab7c7d5317f11667",
            "1266df5f4c914d36beb2e76f418aa14f",
            "05781f308b80430795c34466bf256a96",
            "04f0f6580019439ba809778fdfd5f6d8",
            "d8c9ec77d41546e892c8d2795919aa8c",
            "60b83c3d7a944232b4a13748a171223a",
            "57af322a3ba947168e09ff7da4af74f2"
          ]
        },
        "id": "BtBh7H0hXFrD",
        "outputId": "37dd17c0-0256-4863-88d0-add7092a5e37"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee85f27b3aa240c2b280a63826aa3104"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.3\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. Xformers = 0.0.24. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/quantizers/auto.py:155: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f3b925fc186411486ad8eb40d2334bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b227075839a0466aad8544cd1cbb6aff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/971 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9770e674657540b39e8393b5bb237481"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41d02f5a1bb54ef0ac6119392245bcf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5067323ca3344923a038a552dbaecdf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a18a019976345daa50022746b580d62"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = True,\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pobd-hTNX7iv",
        "outputId": "f77fc50b-26ee-4b4f-84ec-f2700d745207"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Laden des lokalen Datensatzes\n",
        "with open('data_qa.json', 'r', encoding='utf-8') as file:\n",
        "    data_qa = json.load(file)\n",
        "\n",
        "EOS_TOKEN = \"[EOS]\"  # Beispiel für ein EOS-Token, anpassen nach Bedarf\n",
        "\n",
        "def formatting_prompts_func(data_qa):\n",
        "    texts = []\n",
        "    for qa_pair in data_qa:\n",
        "        # Direkte Verwendung des QA-Paares als \"instruction\" und \"output\", \"input\" bleibt leer\n",
        "        instruction = \"Bitte umformulieren der folgenden Frage und Antwort in ein klares Format.\"\n",
        "        input = \"\"  # Kein spezifischer Eingabetext, da der QA-Text bereits die Information enthält\n",
        "        output = qa_pair  # Direkte Verwendung des QA-Paares aus dem Datensatz\n",
        "        text = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n{output}\" + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "# Verarbeitung und Formatierung des Datensatzes\n",
        "formatted_data = formatting_prompts_func(data_qa)\n",
        "\n",
        "# Beispielweise Ausgabe eines formatierten Elements zur Überprüfung\n",
        "print(formatted_data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ63ZCV5X8yT",
        "outputId": "8a7274b7-5e82-4426-9840-9a31d53749bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "Bitte umformulieren der folgenden Frage und Antwort in ein klares Format.\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            " Frage: Im Kontext des Kapitels 9.1, was bezeichnen Phänomene üblicherweise?\n",
            "Antwort: Phänomene stellen typische Verhaltenseffekte dar.\n",
            "\n",
            "Frage: Im Kontexte der Beschreibung in Kapitel 4.2 und 9.1, wer sind Kahneman, Tversky, Thaler und Sunstein?\n",
            "Antwort: Kahneman, Tversky, Thaler und Sunstein sind Forscher, deren Beobachtungen zu allgemeinem Lehrgut für Entscheidungspsychologie gestellt haben.\n",
            "\n",
            "Frage: Im Kontext von Kapitel 9.1, wie beschrieben diese Zusammenfassung?\n",
            "Antswer: Diese Zusammenfassung geht zurück auf Beobachtungen von Kahneman, Tversky, Thaler und Sunstein.[EOS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Angenommen, formatted_data ist eine Liste von formatierten Texten\n",
        "# Beispiel für formatted_data:\n",
        "# formatted_data = [\"### Instruction:\\nFrage ... Antwort ... [EOS]\", \"...\"]\n",
        "\n",
        "# Konvertieren von formatted_data in ein Dataset-Objekt\n",
        "dataset = Dataset.from_dict({\"text\": formatted_data})\n"
      ],
      "metadata": {
        "id": "nHZ1jBE5Zuu8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Training\n",
        "\n",
        "(das Training kann 10-30 Minuten dauern, je nach Größe des Datensatzes auch länger)\n",
        "\n",
        "*  Hyperparameter für das Training (können angepasst werden um das Training zu optimieren)\n",
        "*  Darstellen der Ressourcen vor und nach dem Training\n",
        "*  Trainingsverlauf (hier den angegebenen Wert beachten. Dies ist der Verlustwert und er sollte gegen 0 gehen. Sollte dieser steigen, so wäre es nachteilig für das Training)"
      ],
      "metadata": {
        "id": "WbQIj0zpkSCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "import torch\n",
        "\n",
        "# Konvertieren von formatted_data in ein Dataset-Objekt (vorausgesetzt, formatted_data ist eine Liste von Strings)\n",
        "dataset = Dataset.from_dict({\"text\": formatted_data})\n",
        "\n",
        "# Anschließende Anpassungen und Initialisierung des Trainers\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,  # Verwenden Sie das konvertierte Dataset-Objekt hier\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=128,  # Stellen Sie sicher, dass diese Zahl geeignet ist für Ihre Daten\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "8e31251965e14543aec0e399833a83a2",
            "0be03905e5ca4185b1d972a10265aa2b",
            "75d828789fb148d6918540e0f0cbf382",
            "7644ea0845784b3789ff358c540194f7",
            "f77dab04c2ad4bb2b8c5c4257da59f50",
            "424ee202847f4faf9074f292a90ae9fa",
            "d48343d5a89f42bfb04366c3f06e41ce",
            "d6ef058bb92942e2b59dc89ab285b5c9",
            "ecd2a2ee252c4f908aea4432dcca889d",
            "68fa6677094946399acfdaa55aac7f6c",
            "faa49b7753e545dfb9e469a7b64af641"
          ]
        },
        "id": "feWUHsO2Zet1",
        "outputId": "a0ef7dec-4b25-451e-947a-a189c62107bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/24 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e31251965e14543aec0e399833a83a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Ck1Odi8daGwa",
        "outputId": "beefe395-1c0a-47ec-d22f-9b0783c8e49a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "4.625 GB of memory reserved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oq9AjAfeaJKX",
        "outputId": "71ba7fa5-3fc4-4e2b-ee9c-bab98ac896fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 24 | Num Epochs = 20\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 60\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 04:22, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.176000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.276800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.724300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.669700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.259000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.918200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.722400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.707000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.501100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.448900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.362100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.358700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.173000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.224400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.188100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.131100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.118200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.092100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.098400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.052100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.055700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.047800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.051000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.050500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.041500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.074800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.048000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.038200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.041900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.047200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.043000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.038600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.039200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.034600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.037600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.037000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.033800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.034400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.033200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.036200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.031700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.033600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.031500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.030700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.032500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.034800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.035700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.030900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.030200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show final memory and time stats (optional)\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qm_TlFZaM8I",
        "outputId": "0f78235a-fe8d-46e4-cfe5-68b576670394"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "278.8181 seconds used for training.\n",
            "4.65 minutes used for training.\n",
            "Peak reserved memory = 5.107 GB.\n",
            "Peak reserved memory for training = 0.482 GB.\n",
            "Peak reserved memory % of max memory = 34.628 %.\n",
            "Peak reserved memory for training % of max memory = 3.268 %.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Speichern des Modells und des Adapters\n",
        "\n",
        "(dies kann bis 20 Minuten dauern)\n",
        "\n",
        "*  Zunächst wird der trainierte Adapter gespeichert\n",
        "*  Nun wird das Modell im 4b-quantisierten Format *.gguf gespeichert"
      ],
      "metadata": {
        "id": "1qCC8cl7kwSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora_model\") # Local saving\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# Save to q4_k_m GGUF\n",
        "model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ4H1v41bUdK",
        "outputId": "b7d0f94c-e236-44ac-da15-3e06d5156d6f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 5.81 out of 12.67 RAM for saving.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 19/32 [00:01<00:01, 12.04it/s]We will save to Disk and not RAM now.\n",
            "100%|██████████| 32/32 [01:12<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Unsloth: Saving model/pytorch_model-00001-of-00003.bin...\n",
            "Unsloth: Saving model/pytorch_model-00002-of-00003.bin...\n",
            "Unsloth: Saving model/pytorch_model-00003-of-00003.bin...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Converting mistral model. Can use fast conversion = True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GUUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to q4_k_m will take 20 minutes.\n",
            " \"-____-\"     In total, you will have to wait around 26 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at model into f16 GGUF format.\n",
            "The output location will be ./model-unsloth.F16.gguf\n",
            "This will take 3 minutes...\n",
            "Loading model file model/pytorch_model-00001-of-00003.bin\n",
            "Loading model file model/pytorch_model-00001-of-00003.bin\n",
            "Loading model file model/pytorch_model-00002-of-00003.bin\n",
            "Loading model file model/pytorch_model-00003-of-00003.bin\n",
            "params = Params(n_vocab=32000, n_embd=4096, n_layer=32, n_ctx=32768, n_ff=14336, n_head=32, n_head_kv=8, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=10000.0, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=<GGMLFileType.MostlyF16: 1>, path_model=PosixPath('model'))\n",
            "Found vocab files: {'spm': PosixPath('model/tokenizer.model'), 'bpe': None, 'hfft': PosixPath('model/tokenizer.json')}\n",
            "Loading vocab file PosixPath('model/tokenizer.json'), type 'hfft'\n",
            "fname_tokenizer: model\n",
            "Vocab info: <HfVocab with 32000 base tokens and 0 added tokens>\n",
            "Special vocab info: <SpecialVocab with 0 merges, special tokens {'bos': 1, 'eos': 2, 'unk': 0, 'pad': 0}, add special tokens {'bos': True, 'eos': False}>\n",
            "Permuting layer 0\n",
            "Permuting layer 1\n",
            "Permuting layer 2\n",
            "Permuting layer 3\n",
            "Permuting layer 4\n",
            "Permuting layer 5\n",
            "Permuting layer 6\n",
            "Permuting layer 7\n",
            "Permuting layer 8\n",
            "Permuting layer 9\n",
            "Permuting layer 10\n",
            "Permuting layer 11\n",
            "Permuting layer 12\n",
            "Permuting layer 13\n",
            "Permuting layer 14\n",
            "Permuting layer 15\n",
            "Permuting layer 16\n",
            "Permuting layer 17\n",
            "Permuting layer 18\n",
            "Permuting layer 19\n",
            "Permuting layer 20\n",
            "Permuting layer 21\n",
            "Permuting layer 22\n",
            "Permuting layer 23\n",
            "Permuting layer 24\n",
            "Permuting layer 25\n",
            "Permuting layer 26\n",
            "Permuting layer 27\n",
            "Permuting layer 28\n",
            "Permuting layer 29\n",
            "Permuting layer 30\n",
            "Permuting layer 31\n",
            "model.embed_tokens.weight                        -> token_embd.weight                        | F16    | [32000, 4096]\n",
            "model.layers.0.self_attn.q_proj.weight           -> blk.0.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.0.self_attn.k_proj.weight           -> blk.0.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.0.self_attn.v_proj.weight           -> blk.0.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.0.self_attn.o_proj.weight           -> blk.0.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.0.mlp.gate_proj.weight              -> blk.0.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.0.mlp.up_proj.weight                -> blk.0.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.0.mlp.down_proj.weight              -> blk.0.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.0.input_layernorm.weight            -> blk.0.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.0.post_attention_layernorm.weight   -> blk.0.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.1.self_attn.q_proj.weight           -> blk.1.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.1.self_attn.k_proj.weight           -> blk.1.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.1.self_attn.v_proj.weight           -> blk.1.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.1.self_attn.o_proj.weight           -> blk.1.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.1.mlp.gate_proj.weight              -> blk.1.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.1.mlp.up_proj.weight                -> blk.1.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.1.mlp.down_proj.weight              -> blk.1.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.1.input_layernorm.weight            -> blk.1.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.1.post_attention_layernorm.weight   -> blk.1.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.2.self_attn.q_proj.weight           -> blk.2.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.2.self_attn.k_proj.weight           -> blk.2.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.2.self_attn.v_proj.weight           -> blk.2.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.2.self_attn.o_proj.weight           -> blk.2.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.2.mlp.gate_proj.weight              -> blk.2.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.2.mlp.up_proj.weight                -> blk.2.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.2.mlp.down_proj.weight              -> blk.2.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.2.input_layernorm.weight            -> blk.2.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.2.post_attention_layernorm.weight   -> blk.2.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.3.self_attn.q_proj.weight           -> blk.3.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.3.self_attn.k_proj.weight           -> blk.3.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.3.self_attn.v_proj.weight           -> blk.3.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.3.self_attn.o_proj.weight           -> blk.3.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.3.mlp.gate_proj.weight              -> blk.3.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.3.mlp.up_proj.weight                -> blk.3.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.3.mlp.down_proj.weight              -> blk.3.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.3.input_layernorm.weight            -> blk.3.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.3.post_attention_layernorm.weight   -> blk.3.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.4.self_attn.q_proj.weight           -> blk.4.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.4.self_attn.k_proj.weight           -> blk.4.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.4.self_attn.v_proj.weight           -> blk.4.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.4.self_attn.o_proj.weight           -> blk.4.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.4.mlp.gate_proj.weight              -> blk.4.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.4.mlp.up_proj.weight                -> blk.4.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.4.mlp.down_proj.weight              -> blk.4.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.4.input_layernorm.weight            -> blk.4.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.4.post_attention_layernorm.weight   -> blk.4.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.5.self_attn.q_proj.weight           -> blk.5.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.5.self_attn.k_proj.weight           -> blk.5.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.5.self_attn.v_proj.weight           -> blk.5.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.5.self_attn.o_proj.weight           -> blk.5.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.5.mlp.gate_proj.weight              -> blk.5.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.5.mlp.up_proj.weight                -> blk.5.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.5.mlp.down_proj.weight              -> blk.5.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.5.input_layernorm.weight            -> blk.5.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.5.post_attention_layernorm.weight   -> blk.5.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.6.self_attn.q_proj.weight           -> blk.6.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.6.self_attn.k_proj.weight           -> blk.6.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.6.self_attn.v_proj.weight           -> blk.6.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.6.self_attn.o_proj.weight           -> blk.6.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.6.mlp.gate_proj.weight              -> blk.6.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.6.mlp.up_proj.weight                -> blk.6.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.6.mlp.down_proj.weight              -> blk.6.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.6.input_layernorm.weight            -> blk.6.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.6.post_attention_layernorm.weight   -> blk.6.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.7.self_attn.q_proj.weight           -> blk.7.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.7.self_attn.k_proj.weight           -> blk.7.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.7.self_attn.v_proj.weight           -> blk.7.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.7.self_attn.o_proj.weight           -> blk.7.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.7.mlp.gate_proj.weight              -> blk.7.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.7.mlp.up_proj.weight                -> blk.7.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.7.mlp.down_proj.weight              -> blk.7.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.7.input_layernorm.weight            -> blk.7.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.7.post_attention_layernorm.weight   -> blk.7.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.8.self_attn.q_proj.weight           -> blk.8.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.8.self_attn.k_proj.weight           -> blk.8.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.8.self_attn.v_proj.weight           -> blk.8.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.8.self_attn.o_proj.weight           -> blk.8.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.8.mlp.gate_proj.weight              -> blk.8.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.8.mlp.up_proj.weight                -> blk.8.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.8.mlp.down_proj.weight              -> blk.8.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.8.input_layernorm.weight            -> blk.8.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.8.post_attention_layernorm.weight   -> blk.8.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.9.self_attn.q_proj.weight           -> blk.9.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.9.self_attn.k_proj.weight           -> blk.9.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.9.self_attn.v_proj.weight           -> blk.9.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.9.self_attn.o_proj.weight           -> blk.9.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.9.mlp.gate_proj.weight              -> blk.9.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.9.mlp.up_proj.weight                -> blk.9.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.9.mlp.down_proj.weight              -> blk.9.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.9.input_layernorm.weight            -> blk.9.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.9.post_attention_layernorm.weight   -> blk.9.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.10.self_attn.q_proj.weight          -> blk.10.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.10.self_attn.k_proj.weight          -> blk.10.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.10.self_attn.v_proj.weight          -> blk.10.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.10.self_attn.o_proj.weight          -> blk.10.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.10.mlp.gate_proj.weight             -> blk.10.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.10.mlp.up_proj.weight               -> blk.10.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.10.mlp.down_proj.weight             -> blk.10.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.10.input_layernorm.weight           -> blk.10.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.10.post_attention_layernorm.weight  -> blk.10.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.11.self_attn.q_proj.weight          -> blk.11.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.11.self_attn.k_proj.weight          -> blk.11.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.11.self_attn.v_proj.weight          -> blk.11.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.11.self_attn.o_proj.weight          -> blk.11.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.11.mlp.gate_proj.weight             -> blk.11.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.11.mlp.up_proj.weight               -> blk.11.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.11.mlp.down_proj.weight             -> blk.11.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.11.input_layernorm.weight           -> blk.11.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.11.post_attention_layernorm.weight  -> blk.11.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.12.self_attn.q_proj.weight          -> blk.12.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.12.self_attn.k_proj.weight          -> blk.12.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.12.self_attn.v_proj.weight          -> blk.12.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.12.self_attn.o_proj.weight          -> blk.12.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.12.mlp.gate_proj.weight             -> blk.12.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.12.mlp.up_proj.weight               -> blk.12.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.12.mlp.down_proj.weight             -> blk.12.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.12.input_layernorm.weight           -> blk.12.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.12.post_attention_layernorm.weight  -> blk.12.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.13.self_attn.q_proj.weight          -> blk.13.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.13.self_attn.k_proj.weight          -> blk.13.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.13.self_attn.v_proj.weight          -> blk.13.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.13.self_attn.o_proj.weight          -> blk.13.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.13.mlp.gate_proj.weight             -> blk.13.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.13.mlp.up_proj.weight               -> blk.13.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.13.mlp.down_proj.weight             -> blk.13.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.13.input_layernorm.weight           -> blk.13.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.13.post_attention_layernorm.weight  -> blk.13.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.14.self_attn.q_proj.weight          -> blk.14.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.14.self_attn.k_proj.weight          -> blk.14.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.14.self_attn.v_proj.weight          -> blk.14.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.14.self_attn.o_proj.weight          -> blk.14.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.14.mlp.gate_proj.weight             -> blk.14.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.14.mlp.up_proj.weight               -> blk.14.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.14.mlp.down_proj.weight             -> blk.14.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.14.input_layernorm.weight           -> blk.14.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.14.post_attention_layernorm.weight  -> blk.14.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.15.self_attn.q_proj.weight          -> blk.15.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.15.self_attn.k_proj.weight          -> blk.15.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.15.self_attn.v_proj.weight          -> blk.15.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.15.self_attn.o_proj.weight          -> blk.15.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.15.mlp.gate_proj.weight             -> blk.15.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.15.mlp.up_proj.weight               -> blk.15.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.15.mlp.down_proj.weight             -> blk.15.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.15.input_layernorm.weight           -> blk.15.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.15.post_attention_layernorm.weight  -> blk.15.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.16.self_attn.q_proj.weight          -> blk.16.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.16.self_attn.k_proj.weight          -> blk.16.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.16.self_attn.v_proj.weight          -> blk.16.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.16.self_attn.o_proj.weight          -> blk.16.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.16.mlp.gate_proj.weight             -> blk.16.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.16.mlp.up_proj.weight               -> blk.16.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.16.mlp.down_proj.weight             -> blk.16.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.16.input_layernorm.weight           -> blk.16.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.16.post_attention_layernorm.weight  -> blk.16.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.17.self_attn.q_proj.weight          -> blk.17.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.17.self_attn.k_proj.weight          -> blk.17.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.17.self_attn.v_proj.weight          -> blk.17.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.17.self_attn.o_proj.weight          -> blk.17.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.17.mlp.gate_proj.weight             -> blk.17.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.17.mlp.up_proj.weight               -> blk.17.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.17.mlp.down_proj.weight             -> blk.17.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.17.input_layernorm.weight           -> blk.17.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.17.post_attention_layernorm.weight  -> blk.17.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.18.self_attn.q_proj.weight          -> blk.18.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.18.self_attn.k_proj.weight          -> blk.18.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.18.self_attn.v_proj.weight          -> blk.18.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.18.self_attn.o_proj.weight          -> blk.18.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.18.mlp.gate_proj.weight             -> blk.18.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.18.mlp.up_proj.weight               -> blk.18.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.18.mlp.down_proj.weight             -> blk.18.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.18.input_layernorm.weight           -> blk.18.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.18.post_attention_layernorm.weight  -> blk.18.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.19.self_attn.q_proj.weight          -> blk.19.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.19.self_attn.k_proj.weight          -> blk.19.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.19.self_attn.v_proj.weight          -> blk.19.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.19.self_attn.o_proj.weight          -> blk.19.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.19.mlp.gate_proj.weight             -> blk.19.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.19.mlp.up_proj.weight               -> blk.19.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.19.mlp.down_proj.weight             -> blk.19.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.19.input_layernorm.weight           -> blk.19.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.19.post_attention_layernorm.weight  -> blk.19.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.20.self_attn.q_proj.weight          -> blk.20.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.20.self_attn.k_proj.weight          -> blk.20.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.20.self_attn.v_proj.weight          -> blk.20.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.20.self_attn.o_proj.weight          -> blk.20.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.20.mlp.gate_proj.weight             -> blk.20.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.20.mlp.up_proj.weight               -> blk.20.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.20.mlp.down_proj.weight             -> blk.20.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.20.input_layernorm.weight           -> blk.20.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.20.post_attention_layernorm.weight  -> blk.20.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.21.self_attn.q_proj.weight          -> blk.21.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.21.self_attn.k_proj.weight          -> blk.21.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.21.self_attn.v_proj.weight          -> blk.21.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.21.self_attn.o_proj.weight          -> blk.21.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.21.mlp.gate_proj.weight             -> blk.21.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.21.mlp.up_proj.weight               -> blk.21.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.21.mlp.down_proj.weight             -> blk.21.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.21.input_layernorm.weight           -> blk.21.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.21.post_attention_layernorm.weight  -> blk.21.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.22.self_attn.q_proj.weight          -> blk.22.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.22.self_attn.k_proj.weight          -> blk.22.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.22.self_attn.v_proj.weight          -> blk.22.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.22.self_attn.o_proj.weight          -> blk.22.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.22.mlp.gate_proj.weight             -> blk.22.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.22.mlp.up_proj.weight               -> blk.22.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.22.mlp.down_proj.weight             -> blk.22.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.22.input_layernorm.weight           -> blk.22.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.22.post_attention_layernorm.weight  -> blk.22.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.23.self_attn.q_proj.weight          -> blk.23.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.23.self_attn.k_proj.weight          -> blk.23.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.23.self_attn.v_proj.weight          -> blk.23.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.23.self_attn.o_proj.weight          -> blk.23.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.23.mlp.gate_proj.weight             -> blk.23.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.23.mlp.up_proj.weight               -> blk.23.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.23.mlp.down_proj.weight             -> blk.23.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.23.input_layernorm.weight           -> blk.23.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.23.post_attention_layernorm.weight  -> blk.23.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.24.self_attn.q_proj.weight          -> blk.24.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.24.self_attn.k_proj.weight          -> blk.24.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.24.self_attn.v_proj.weight          -> blk.24.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.24.self_attn.o_proj.weight          -> blk.24.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.24.mlp.gate_proj.weight             -> blk.24.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.24.mlp.up_proj.weight               -> blk.24.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.24.mlp.down_proj.weight             -> blk.24.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.24.input_layernorm.weight           -> blk.24.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.24.post_attention_layernorm.weight  -> blk.24.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.25.self_attn.q_proj.weight          -> blk.25.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.25.self_attn.k_proj.weight          -> blk.25.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.25.self_attn.v_proj.weight          -> blk.25.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.25.self_attn.o_proj.weight          -> blk.25.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.25.mlp.gate_proj.weight             -> blk.25.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.25.mlp.up_proj.weight               -> blk.25.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.25.mlp.down_proj.weight             -> blk.25.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.25.input_layernorm.weight           -> blk.25.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.25.post_attention_layernorm.weight  -> blk.25.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.26.self_attn.q_proj.weight          -> blk.26.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.26.self_attn.k_proj.weight          -> blk.26.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.26.self_attn.v_proj.weight          -> blk.26.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.26.self_attn.o_proj.weight          -> blk.26.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.26.mlp.gate_proj.weight             -> blk.26.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.26.mlp.up_proj.weight               -> blk.26.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.26.mlp.down_proj.weight             -> blk.26.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.26.input_layernorm.weight           -> blk.26.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.26.post_attention_layernorm.weight  -> blk.26.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.27.self_attn.q_proj.weight          -> blk.27.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.27.self_attn.k_proj.weight          -> blk.27.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.27.self_attn.v_proj.weight          -> blk.27.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.27.self_attn.o_proj.weight          -> blk.27.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.27.mlp.gate_proj.weight             -> blk.27.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.27.mlp.up_proj.weight               -> blk.27.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.27.mlp.down_proj.weight             -> blk.27.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.27.input_layernorm.weight           -> blk.27.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.27.post_attention_layernorm.weight  -> blk.27.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.28.self_attn.q_proj.weight          -> blk.28.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.28.self_attn.k_proj.weight          -> blk.28.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.28.self_attn.v_proj.weight          -> blk.28.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.28.self_attn.o_proj.weight          -> blk.28.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.28.mlp.gate_proj.weight             -> blk.28.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.28.mlp.up_proj.weight               -> blk.28.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.28.mlp.down_proj.weight             -> blk.28.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.28.input_layernorm.weight           -> blk.28.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.28.post_attention_layernorm.weight  -> blk.28.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.29.self_attn.q_proj.weight          -> blk.29.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.29.self_attn.k_proj.weight          -> blk.29.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.29.self_attn.v_proj.weight          -> blk.29.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.29.self_attn.o_proj.weight          -> blk.29.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.29.mlp.gate_proj.weight             -> blk.29.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.29.mlp.up_proj.weight               -> blk.29.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.29.mlp.down_proj.weight             -> blk.29.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.29.input_layernorm.weight           -> blk.29.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.29.post_attention_layernorm.weight  -> blk.29.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.30.self_attn.q_proj.weight          -> blk.30.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.30.self_attn.k_proj.weight          -> blk.30.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.30.self_attn.v_proj.weight          -> blk.30.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.30.self_attn.o_proj.weight          -> blk.30.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.30.mlp.gate_proj.weight             -> blk.30.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.30.mlp.up_proj.weight               -> blk.30.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.30.mlp.down_proj.weight             -> blk.30.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.30.input_layernorm.weight           -> blk.30.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.30.post_attention_layernorm.weight  -> blk.30.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.31.self_attn.q_proj.weight          -> blk.31.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.31.self_attn.k_proj.weight          -> blk.31.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.31.self_attn.v_proj.weight          -> blk.31.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.31.self_attn.o_proj.weight          -> blk.31.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.31.mlp.gate_proj.weight             -> blk.31.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.31.mlp.up_proj.weight               -> blk.31.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.31.mlp.down_proj.weight             -> blk.31.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.31.input_layernorm.weight           -> blk.31.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.31.post_attention_layernorm.weight  -> blk.31.ffn_norm.weight                   | F16    | [4096]\n",
            "model.norm.weight                                -> output_norm.weight                       | F16    | [4096]\n",
            "lm_head.weight                                   -> output.weight                            | F16    | [32000, 4096]\n",
            "Writing model-unsloth.F16.gguf, format 1\n",
            "Ignoring added_tokens.json since model matches vocab size without it.\n",
            "gguf: This GGUF file is for Little Endian only\n",
            "gguf: Setting special token type bos to 1\n",
            "gguf: Setting special token type eos to 2\n",
            "gguf: Setting special token type unk to 0\n",
            "gguf: Setting special token type pad to 0\n",
            "gguf: Setting add_bos_token to True\n",
            "gguf: Setting add_eos_token to False\n",
            "[  1/291] Writing tensor token_embd.weight                      | size  32000 x   4096  | type F16  | T+   1\n",
            "[  2/291] Writing tensor blk.0.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   2\n",
            "[  3/291] Writing tensor blk.0.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   2\n",
            "[  4/291] Writing tensor blk.0.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   2\n",
            "[  5/291] Writing tensor blk.0.attn_output.weight               | size   4096 x   4096  | type F16  | T+   2\n",
            "[  6/291] Writing tensor blk.0.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   3\n",
            "[  7/291] Writing tensor blk.0.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   4\n",
            "[  8/291] Writing tensor blk.0.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+   5\n",
            "[  9/291] Writing tensor blk.0.attn_norm.weight                 | size   4096           | type F32  | T+   5\n",
            "[ 10/291] Writing tensor blk.0.ffn_norm.weight                  | size   4096           | type F32  | T+   5\n",
            "[ 11/291] Writing tensor blk.1.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   5\n",
            "[ 12/291] Writing tensor blk.1.attn_k.weight                    | size   1024 x   4096  | type F16  | T+   5\n",
            "[ 13/291] Writing tensor blk.1.attn_v.weight                    | size   1024 x   4096  | type F16  | T+   6\n",
            "[ 14/291] Writing tensor blk.1.attn_output.weight               | size   4096 x   4096  | type F16  | T+   6\n",
            "[ 15/291] Writing tensor blk.1.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+   7\n",
            "[ 16/291] Writing tensor blk.1.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+   8\n",
            "[ 17/291] Writing tensor blk.1.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  10\n",
            "[ 18/291] Writing tensor blk.1.attn_norm.weight                 | size   4096           | type F32  | T+  15\n",
            "[ 19/291] Writing tensor blk.1.ffn_norm.weight                  | size   4096           | type F32  | T+  15\n",
            "[ 20/291] Writing tensor blk.2.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  15\n",
            "[ 21/291] Writing tensor blk.2.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  15\n",
            "[ 22/291] Writing tensor blk.2.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  15\n",
            "[ 23/291] Writing tensor blk.2.attn_output.weight               | size   4096 x   4096  | type F16  | T+  15\n",
            "[ 24/291] Writing tensor blk.2.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  17\n",
            "[ 25/291] Writing tensor blk.2.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  18\n",
            "[ 26/291] Writing tensor blk.2.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  20\n",
            "[ 27/291] Writing tensor blk.2.attn_norm.weight                 | size   4096           | type F32  | T+  25\n",
            "[ 28/291] Writing tensor blk.2.ffn_norm.weight                  | size   4096           | type F32  | T+  25\n",
            "[ 29/291] Writing tensor blk.3.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  25\n",
            "[ 30/291] Writing tensor blk.3.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  25\n",
            "[ 31/291] Writing tensor blk.3.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  25\n",
            "[ 32/291] Writing tensor blk.3.attn_output.weight               | size   4096 x   4096  | type F16  | T+  25\n",
            "[ 33/291] Writing tensor blk.3.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  26\n",
            "[ 34/291] Writing tensor blk.3.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  27\n",
            "[ 35/291] Writing tensor blk.3.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  30\n",
            "[ 36/291] Writing tensor blk.3.attn_norm.weight                 | size   4096           | type F32  | T+  30\n",
            "[ 37/291] Writing tensor blk.3.ffn_norm.weight                  | size   4096           | type F32  | T+  30\n",
            "[ 38/291] Writing tensor blk.4.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  30\n",
            "[ 39/291] Writing tensor blk.4.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  30\n",
            "[ 40/291] Writing tensor blk.4.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  30\n",
            "[ 41/291] Writing tensor blk.4.attn_output.weight               | size   4096 x   4096  | type F16  | T+  31\n",
            "[ 42/291] Writing tensor blk.4.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  32\n",
            "[ 43/291] Writing tensor blk.4.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  35\n",
            "[ 44/291] Writing tensor blk.4.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  35\n",
            "[ 45/291] Writing tensor blk.4.attn_norm.weight                 | size   4096           | type F32  | T+  35\n",
            "[ 46/291] Writing tensor blk.4.ffn_norm.weight                  | size   4096           | type F32  | T+  35\n",
            "[ 47/291] Writing tensor blk.5.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  35\n",
            "[ 48/291] Writing tensor blk.5.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  36\n",
            "[ 49/291] Writing tensor blk.5.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  36\n",
            "[ 50/291] Writing tensor blk.5.attn_output.weight               | size   4096 x   4096  | type F16  | T+  36\n",
            "[ 51/291] Writing tensor blk.5.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  37\n",
            "[ 52/291] Writing tensor blk.5.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  38\n",
            "[ 53/291] Writing tensor blk.5.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  40\n",
            "[ 54/291] Writing tensor blk.5.attn_norm.weight                 | size   4096           | type F32  | T+  45\n",
            "[ 55/291] Writing tensor blk.5.ffn_norm.weight                  | size   4096           | type F32  | T+  45\n",
            "[ 56/291] Writing tensor blk.6.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  45\n",
            "[ 57/291] Writing tensor blk.6.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  45\n",
            "[ 58/291] Writing tensor blk.6.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  45\n",
            "[ 59/291] Writing tensor blk.6.attn_output.weight               | size   4096 x   4096  | type F16  | T+  45\n",
            "[ 60/291] Writing tensor blk.6.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  46\n",
            "[ 61/291] Writing tensor blk.6.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  47\n",
            "[ 62/291] Writing tensor blk.6.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  48\n",
            "[ 63/291] Writing tensor blk.6.attn_norm.weight                 | size   4096           | type F32  | T+  50\n",
            "[ 64/291] Writing tensor blk.6.ffn_norm.weight                  | size   4096           | type F32  | T+  50\n",
            "[ 65/291] Writing tensor blk.7.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  50\n",
            "[ 66/291] Writing tensor blk.7.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  50\n",
            "[ 67/291] Writing tensor blk.7.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  50\n",
            "[ 68/291] Writing tensor blk.7.attn_output.weight               | size   4096 x   4096  | type F16  | T+  50\n",
            "[ 69/291] Writing tensor blk.7.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  51\n",
            "[ 70/291] Writing tensor blk.7.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  53\n",
            "[ 71/291] Writing tensor blk.7.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  54\n",
            "[ 72/291] Writing tensor blk.7.attn_norm.weight                 | size   4096           | type F32  | T+  56\n",
            "[ 73/291] Writing tensor blk.7.ffn_norm.weight                  | size   4096           | type F32  | T+  56\n",
            "[ 74/291] Writing tensor blk.8.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  56\n",
            "[ 75/291] Writing tensor blk.8.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  56\n",
            "[ 76/291] Writing tensor blk.8.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  56\n",
            "[ 77/291] Writing tensor blk.8.attn_output.weight               | size   4096 x   4096  | type F16  | T+  57\n",
            "[ 78/291] Writing tensor blk.8.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  57\n",
            "[ 79/291] Writing tensor blk.8.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  61\n",
            "[ 80/291] Writing tensor blk.8.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  61\n",
            "[ 81/291] Writing tensor blk.8.attn_norm.weight                 | size   4096           | type F32  | T+  66\n",
            "[ 82/291] Writing tensor blk.8.ffn_norm.weight                  | size   4096           | type F32  | T+  66\n",
            "[ 83/291] Writing tensor blk.9.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  66\n",
            "[ 84/291] Writing tensor blk.9.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  66\n",
            "[ 85/291] Writing tensor blk.9.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  66\n",
            "[ 86/291] Writing tensor blk.9.attn_output.weight               | size   4096 x   4096  | type F16  | T+  66\n",
            "[ 87/291] Writing tensor blk.9.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  67\n",
            "[ 88/291] Writing tensor blk.9.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  68\n",
            "[ 89/291] Writing tensor blk.9.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  69\n",
            "[ 90/291] Writing tensor blk.9.attn_norm.weight                 | size   4096           | type F32  | T+  71\n",
            "[ 91/291] Writing tensor blk.9.ffn_norm.weight                  | size   4096           | type F32  | T+  71\n",
            "[ 92/291] Writing tensor blk.10.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  71\n",
            "[ 93/291] Writing tensor blk.10.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  71\n",
            "[ 94/291] Writing tensor blk.10.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  71\n",
            "[ 95/291] Writing tensor blk.10.attn_output.weight              | size   4096 x   4096  | type F16  | T+  73\n",
            "[ 96/291] Writing tensor blk.10.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  73\n",
            "[ 97/291] Writing tensor blk.10.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  74\n",
            "[ 98/291] Writing tensor blk.10.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  75\n",
            "[ 99/291] Writing tensor blk.10.attn_norm.weight                | size   4096           | type F32  | T+  76\n",
            "[100/291] Writing tensor blk.10.ffn_norm.weight                 | size   4096           | type F32  | T+  76\n",
            "[101/291] Writing tensor blk.11.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  76\n",
            "[102/291] Writing tensor blk.11.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  76\n",
            "[103/291] Writing tensor blk.11.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  76\n",
            "[104/291] Writing tensor blk.11.attn_output.weight              | size   4096 x   4096  | type F16  | T+  76\n",
            "[105/291] Writing tensor blk.11.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  78\n",
            "[106/291] Writing tensor blk.11.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  80\n",
            "[107/291] Writing tensor blk.11.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  81\n",
            "[108/291] Writing tensor blk.11.attn_norm.weight                | size   4096           | type F32  | T+  86\n",
            "[109/291] Writing tensor blk.11.ffn_norm.weight                 | size   4096           | type F32  | T+  86\n",
            "[110/291] Writing tensor blk.12.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  86\n",
            "[111/291] Writing tensor blk.12.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  86\n",
            "[112/291] Writing tensor blk.12.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  86\n",
            "[113/291] Writing tensor blk.12.attn_output.weight              | size   4096 x   4096  | type F16  | T+  86\n",
            "[114/291] Writing tensor blk.12.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  88\n",
            "[115/291] Writing tensor blk.12.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  89\n",
            "[116/291] Writing tensor blk.12.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  90\n",
            "[117/291] Writing tensor blk.12.attn_norm.weight                | size   4096           | type F32  | T+  91\n",
            "[118/291] Writing tensor blk.12.ffn_norm.weight                 | size   4096           | type F32  | T+  91\n",
            "[119/291] Writing tensor blk.13.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  91\n",
            "[120/291] Writing tensor blk.13.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  91\n",
            "[121/291] Writing tensor blk.13.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  91\n",
            "[122/291] Writing tensor blk.13.attn_output.weight              | size   4096 x   4096  | type F16  | T+  91\n",
            "[123/291] Writing tensor blk.13.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  93\n",
            "[124/291] Writing tensor blk.13.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  96\n",
            "[125/291] Writing tensor blk.13.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  96\n",
            "[126/291] Writing tensor blk.13.attn_norm.weight                | size   4096           | type F32  | T+ 101\n",
            "[127/291] Writing tensor blk.13.ffn_norm.weight                 | size   4096           | type F32  | T+ 101\n",
            "[128/291] Writing tensor blk.14.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 101\n",
            "[129/291] Writing tensor blk.14.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 101\n",
            "[130/291] Writing tensor blk.14.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 101\n",
            "[131/291] Writing tensor blk.14.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 101\n",
            "[132/291] Writing tensor blk.14.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 105\n",
            "[133/291] Writing tensor blk.14.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 107\n",
            "[134/291] Writing tensor blk.14.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 107\n",
            "[135/291] Writing tensor blk.14.attn_norm.weight                | size   4096           | type F32  | T+ 107\n",
            "[136/291] Writing tensor blk.14.ffn_norm.weight                 | size   4096           | type F32  | T+ 107\n",
            "[137/291] Writing tensor blk.15.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 107\n",
            "[138/291] Writing tensor blk.15.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 108\n",
            "[139/291] Writing tensor blk.15.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 108\n",
            "[140/291] Writing tensor blk.15.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 108\n",
            "[141/291] Writing tensor blk.15.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 109\n",
            "[142/291] Writing tensor blk.15.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 110\n",
            "[143/291] Writing tensor blk.15.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 111\n",
            "[144/291] Writing tensor blk.15.attn_norm.weight                | size   4096           | type F32  | T+ 111\n",
            "[145/291] Writing tensor blk.15.ffn_norm.weight                 | size   4096           | type F32  | T+ 111\n",
            "[146/291] Writing tensor blk.16.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 111\n",
            "[147/291] Writing tensor blk.16.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 112\n",
            "[148/291] Writing tensor blk.16.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 112\n",
            "[149/291] Writing tensor blk.16.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 112\n",
            "[150/291] Writing tensor blk.16.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 113\n",
            "[151/291] Writing tensor blk.16.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 114\n",
            "[152/291] Writing tensor blk.16.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 116\n",
            "[153/291] Writing tensor blk.16.attn_norm.weight                | size   4096           | type F32  | T+ 121\n",
            "[154/291] Writing tensor blk.16.ffn_norm.weight                 | size   4096           | type F32  | T+ 121\n",
            "[155/291] Writing tensor blk.17.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 121\n",
            "[156/291] Writing tensor blk.17.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 121\n",
            "[157/291] Writing tensor blk.17.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 121\n",
            "[158/291] Writing tensor blk.17.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 121\n",
            "[159/291] Writing tensor blk.17.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 122\n",
            "[160/291] Writing tensor blk.17.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 123\n",
            "[161/291] Writing tensor blk.17.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 124\n",
            "[162/291] Writing tensor blk.17.attn_norm.weight                | size   4096           | type F32  | T+ 126\n",
            "[163/291] Writing tensor blk.17.ffn_norm.weight                 | size   4096           | type F32  | T+ 126\n",
            "[164/291] Writing tensor blk.18.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 126\n",
            "[165/291] Writing tensor blk.18.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 126\n",
            "[166/291] Writing tensor blk.18.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 126\n",
            "[167/291] Writing tensor blk.18.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 126\n",
            "[168/291] Writing tensor blk.18.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 127\n",
            "[169/291] Writing tensor blk.18.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 131\n",
            "[170/291] Writing tensor blk.18.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 131\n",
            "[171/291] Writing tensor blk.18.attn_norm.weight                | size   4096           | type F32  | T+ 132\n",
            "[172/291] Writing tensor blk.18.ffn_norm.weight                 | size   4096           | type F32  | T+ 132\n",
            "[173/291] Writing tensor blk.19.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 132\n",
            "[174/291] Writing tensor blk.19.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 132\n",
            "[175/291] Writing tensor blk.19.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 132\n",
            "[176/291] Writing tensor blk.19.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 132\n",
            "[177/291] Writing tensor blk.19.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 133\n",
            "[178/291] Writing tensor blk.19.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 136\n",
            "[179/291] Writing tensor blk.19.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 136\n",
            "[180/291] Writing tensor blk.19.attn_norm.weight                | size   4096           | type F32  | T+ 136\n",
            "[181/291] Writing tensor blk.19.ffn_norm.weight                 | size   4096           | type F32  | T+ 136\n",
            "[182/291] Writing tensor blk.20.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 136\n",
            "[183/291] Writing tensor blk.20.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 137\n",
            "[184/291] Writing tensor blk.20.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 137\n",
            "[185/291] Writing tensor blk.20.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 137\n",
            "[186/291] Writing tensor blk.20.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 138\n",
            "[187/291] Writing tensor blk.20.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 139\n",
            "[188/291] Writing tensor blk.20.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 141\n",
            "[189/291] Writing tensor blk.20.attn_norm.weight                | size   4096           | type F32  | T+ 141\n",
            "[190/291] Writing tensor blk.20.ffn_norm.weight                 | size   4096           | type F32  | T+ 141\n",
            "[191/291] Writing tensor blk.21.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 141\n",
            "[192/291] Writing tensor blk.21.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 141\n",
            "[193/291] Writing tensor blk.21.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 141\n",
            "[194/291] Writing tensor blk.21.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 142\n",
            "[195/291] Writing tensor blk.21.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 143\n",
            "[196/291] Writing tensor blk.21.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 146\n",
            "[197/291] Writing tensor blk.21.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 146\n",
            "[198/291] Writing tensor blk.21.attn_norm.weight                | size   4096           | type F32  | T+ 146\n",
            "[199/291] Writing tensor blk.21.ffn_norm.weight                 | size   4096           | type F32  | T+ 146\n",
            "[200/291] Writing tensor blk.22.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 146\n",
            "[201/291] Writing tensor blk.22.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 147\n",
            "[202/291] Writing tensor blk.22.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 147\n",
            "[203/291] Writing tensor blk.22.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 147\n",
            "[204/291] Writing tensor blk.22.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 148\n",
            "[205/291] Writing tensor blk.22.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 151\n",
            "[206/291] Writing tensor blk.22.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 151\n",
            "[207/291] Writing tensor blk.22.attn_norm.weight                | size   4096           | type F32  | T+ 152\n",
            "[208/291] Writing tensor blk.22.ffn_norm.weight                 | size   4096           | type F32  | T+ 152\n",
            "[209/291] Writing tensor blk.23.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 152\n",
            "[210/291] Writing tensor blk.23.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 156\n",
            "[211/291] Writing tensor blk.23.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 156\n",
            "[212/291] Writing tensor blk.23.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 156\n",
            "[213/291] Writing tensor blk.23.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 156\n",
            "[214/291] Writing tensor blk.23.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 157\n",
            "[215/291] Writing tensor blk.23.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 158\n",
            "[216/291] Writing tensor blk.23.attn_norm.weight                | size   4096           | type F32  | T+ 161\n",
            "[217/291] Writing tensor blk.23.ffn_norm.weight                 | size   4096           | type F32  | T+ 161\n",
            "[218/291] Writing tensor blk.24.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 161\n",
            "[219/291] Writing tensor blk.24.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 161\n",
            "[220/291] Writing tensor blk.24.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 161\n",
            "[221/291] Writing tensor blk.24.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 163\n",
            "[222/291] Writing tensor blk.24.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 166\n",
            "[223/291] Writing tensor blk.24.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 166\n",
            "[224/291] Writing tensor blk.24.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 167\n",
            "[225/291] Writing tensor blk.24.attn_norm.weight                | size   4096           | type F32  | T+ 167\n",
            "[226/291] Writing tensor blk.24.ffn_norm.weight                 | size   4096           | type F32  | T+ 167\n",
            "[227/291] Writing tensor blk.25.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 167\n",
            "[228/291] Writing tensor blk.25.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 167\n",
            "[229/291] Writing tensor blk.25.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 167\n",
            "[230/291] Writing tensor blk.25.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 167\n",
            "[231/291] Writing tensor blk.25.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 168\n",
            "[232/291] Writing tensor blk.25.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 170\n",
            "[233/291] Writing tensor blk.25.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 171\n",
            "[234/291] Writing tensor blk.25.attn_norm.weight                | size   4096           | type F32  | T+ 171\n",
            "[235/291] Writing tensor blk.25.ffn_norm.weight                 | size   4096           | type F32  | T+ 171\n",
            "[236/291] Writing tensor blk.26.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 171\n",
            "[237/291] Writing tensor blk.26.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 176\n",
            "[238/291] Writing tensor blk.26.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 176\n",
            "[239/291] Writing tensor blk.26.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 176\n",
            "[240/291] Writing tensor blk.26.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 176\n",
            "[241/291] Writing tensor blk.26.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 177\n",
            "[242/291] Writing tensor blk.26.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 178\n",
            "[243/291] Writing tensor blk.26.attn_norm.weight                | size   4096           | type F32  | T+ 181\n",
            "[244/291] Writing tensor blk.26.ffn_norm.weight                 | size   4096           | type F32  | T+ 181\n",
            "[245/291] Writing tensor blk.27.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 181\n",
            "[246/291] Writing tensor blk.27.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 181\n",
            "[247/291] Writing tensor blk.27.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 181\n",
            "[248/291] Writing tensor blk.27.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 182\n",
            "[249/291] Writing tensor blk.27.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 182\n",
            "[250/291] Writing tensor blk.27.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 186\n",
            "[251/291] Writing tensor blk.27.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 186\n",
            "[252/291] Writing tensor blk.27.attn_norm.weight                | size   4096           | type F32  | T+ 191\n",
            "[253/291] Writing tensor blk.27.ffn_norm.weight                 | size   4096           | type F32  | T+ 191\n",
            "[254/291] Writing tensor blk.28.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 191\n",
            "[255/291] Writing tensor blk.28.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 191\n",
            "[256/291] Writing tensor blk.28.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 191\n",
            "[257/291] Writing tensor blk.28.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 191\n",
            "[258/291] Writing tensor blk.28.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 192\n",
            "[259/291] Writing tensor blk.28.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 196\n",
            "[260/291] Writing tensor blk.28.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 196\n",
            "[261/291] Writing tensor blk.28.attn_norm.weight                | size   4096           | type F32  | T+ 198\n",
            "[262/291] Writing tensor blk.28.ffn_norm.weight                 | size   4096           | type F32  | T+ 198\n",
            "[263/291] Writing tensor blk.29.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 198\n",
            "[264/291] Writing tensor blk.29.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 198\n",
            "[265/291] Writing tensor blk.29.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 198\n",
            "[266/291] Writing tensor blk.29.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 199\n",
            "[267/291] Writing tensor blk.29.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 201\n",
            "[268/291] Writing tensor blk.29.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 201\n",
            "[269/291] Writing tensor blk.29.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 202\n",
            "[270/291] Writing tensor blk.29.attn_norm.weight                | size   4096           | type F32  | T+ 202\n",
            "[271/291] Writing tensor blk.29.ffn_norm.weight                 | size   4096           | type F32  | T+ 202\n",
            "[272/291] Writing tensor blk.30.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 202\n",
            "[273/291] Writing tensor blk.30.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 202\n",
            "[274/291] Writing tensor blk.30.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 202\n",
            "[275/291] Writing tensor blk.30.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 203\n",
            "[276/291] Writing tensor blk.30.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 204\n",
            "[277/291] Writing tensor blk.30.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 206\n",
            "[278/291] Writing tensor blk.30.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 206\n",
            "[279/291] Writing tensor blk.30.attn_norm.weight                | size   4096           | type F32  | T+ 206\n",
            "[280/291] Writing tensor blk.30.ffn_norm.weight                 | size   4096           | type F32  | T+ 206\n",
            "[281/291] Writing tensor blk.31.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 206\n",
            "[282/291] Writing tensor blk.31.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 207\n",
            "[283/291] Writing tensor blk.31.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 207\n",
            "[284/291] Writing tensor blk.31.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 207\n",
            "[285/291] Writing tensor blk.31.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 208\n",
            "[286/291] Writing tensor blk.31.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 209\n",
            "[287/291] Writing tensor blk.31.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 211\n",
            "[288/291] Writing tensor blk.31.attn_norm.weight                | size   4096           | type F32  | T+ 212\n",
            "[289/291] Writing tensor blk.31.ffn_norm.weight                 | size   4096           | type F32  | T+ 212\n",
            "[290/291] Writing tensor output_norm.weight                     | size   4096           | type F32  | T+ 212\n",
            "[291/291] Writing tensor output.weight                          | size  32000 x   4096  | type F16  | T+ 213\n",
            "Wrote model-unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: ./model-unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
            "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_init_cublas: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "main: build = 2436 (131b0584)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing './model-unsloth.F16.gguf' to './model-unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from ./model-unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = .\n",
            "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 32000\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  12:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,32000]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,32000]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "llama_model_quantize_internal: meta size = 735008 bytes\n",
            "[   1/ 291]                    token_embd.weight - [ 4096, 32000,     1,     1], type =    f16, converting to q4_K .. size =   250.00 MiB ->    70.31 MiB\n",
            "[   2/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   3/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   4/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[   5/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   6/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[   7/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[   8/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[   9/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  10/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  11/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  12/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  13/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  14/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  15/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  16/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  17/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  18/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  19/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  20/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  21/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  22/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  23/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  24/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  25/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  26/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  27/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  28/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  29/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  30/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  31/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  32/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  33/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  34/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  35/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  36/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  37/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  38/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  39/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  40/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  41/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  42/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  43/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  44/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  45/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  46/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  47/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  48/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  49/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  50/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  51/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  52/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  53/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  54/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  55/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  56/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  57/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  58/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  59/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  60/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  61/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  62/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  63/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  64/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  65/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  66/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  67/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  68/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  69/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  70/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  71/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  72/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  73/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  74/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  75/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  76/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  77/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  78/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  79/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  80/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  81/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  82/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  83/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  84/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  85/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  86/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  87/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  88/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  89/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  90/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  91/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  92/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  93/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  94/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  95/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  96/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  97/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  98/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  99/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 100/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 101/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 102/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 103/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 104/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 105/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 106/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 107/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 108/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 109/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 110/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 111/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 112/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 113/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 114/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 115/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 116/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 117/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 118/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 119/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 120/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 121/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 122/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 123/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 124/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 125/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 126/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 127/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 128/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 129/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 130/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 131/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 132/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 133/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 134/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 135/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 136/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 137/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 138/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 139/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 140/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 141/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 142/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 143/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 144/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 145/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 146/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 147/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 148/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 149/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 150/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 151/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 152/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 153/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 154/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 155/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 156/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 157/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 158/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 159/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 160/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 161/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 162/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 163/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 164/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 165/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 166/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 167/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 168/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 169/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 170/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 171/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 172/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 173/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 174/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 175/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 176/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 177/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 178/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 179/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 180/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 181/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 182/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 183/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 184/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 185/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 186/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 187/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 188/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 189/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 190/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 191/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 192/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 193/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 194/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 195/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 196/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 197/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 198/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 199/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 200/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 201/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 202/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 203/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 204/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 205/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 206/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 207/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 208/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 209/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 210/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 211/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 212/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 213/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 214/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 215/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 216/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 217/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 218/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 219/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 220/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 221/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 222/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 223/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 224/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 225/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 226/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 227/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 228/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 229/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 230/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 231/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 232/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 233/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 234/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 235/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 236/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 237/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 238/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 239/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 240/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 241/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 242/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 243/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 244/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 245/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 246/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 247/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 248/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 249/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 250/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 251/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 252/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 253/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 254/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 255/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 256/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 257/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 258/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 259/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 260/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 261/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 262/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 263/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 264/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 265/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 266/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 267/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 268/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 269/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 270/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 271/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 272/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 273/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 274/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 275/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 276/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 277/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 278/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 279/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 280/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 281/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 282/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 283/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 284/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 285/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 286/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 287/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 288/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 289/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 290/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                        output.weight - [ 4096, 32000,     1,     1], type =    f16, converting to q6_K .. size =   250.00 MiB ->   102.54 MiB\n",
            "llama_model_quantize_internal: model size  = 13813.02 MB\n",
            "llama_model_quantize_internal: quant size  =  4165.37 MB\n",
            "Unsloth: Conversion completed! Output location: ./model-unsloth.Q4_K_M.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# WICHTIG!!!! Zwischenschritt\n",
        "\n",
        "1.   model-unsloth.Q4_K_M.gguf herunterladen\n",
        "2.   Notebook mit T4-GPU neu starten\n",
        "3.   model-unsloth.Q4_K_M.gguf hochladen\n",
        "4.   Ab hier weitermachen!\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "57Fr7Hi2gNBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Inferenz (Test)"
      ],
      "metadata": {
        "id": "5X0F26PTa8f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Testvorbereitungen\n",
        "\n",
        "\n",
        "\n",
        "*  Instalation aller relevanten Python-Bibs für Ollama\n",
        "*  Erstellen eines Ollama-Modells basierend auf dem trainierten *.gguf-Modells"
      ],
      "metadata": {
        "id": "j-XFl3AllS2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm model-unsloth.F16.gguf\n",
        "!rm -r model\n",
        "!rm -r lora_model\n",
        "!rm -r llama.cpp\n",
        "!rm -r outputs"
      ],
      "metadata": {
        "id": "NnVmDud_ul6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! sudo apt-get install -y pciutils\n",
        "!pip install pypdf2\n",
        "! curl https://ollama.ai/install.sh | sh\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()"
      ],
      "metadata": {
        "id": "u0mqg5aRfYwR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Dateiname definieren\n",
        "filename = 'Modelfile'\n",
        "\n",
        "# Inhalt der Datei\n",
        "content = 'FROM ./model-unsloth.Q4_K_M.gguf'\n",
        "\n",
        "# Datei erstellen und schreiben\n",
        "with open(filename, 'w') as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(f\"Datei '{filename}' wurde erfolgreich erstellt.\")\n",
        "\n",
        "!ollama create ft_mistral -f Modelfile\n",
        "\n",
        "import subprocess\n",
        "\n",
        "# Befehl definieren\n",
        "command = 'ollama create ft_mistral -f Modelfile'\n",
        "\n",
        "# Befehl ausführen\n",
        "process = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# Ausgabe und Fehlerausgabe (falls vorhanden) anzeigen\n",
        "print(process.stdout.decode())\n",
        "if process.stderr:\n",
        "    print(\"Fehler:\", process.stderr.decode())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ql-ynn0bJap",
        "outputId": "4389fbb8-08c8-4411-c9a3-5f6562a10fd9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datei 'Modelfile' wurde erfolgreich erstellt.\n",
            "\u001b[?25ltransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer \n",
            "using already created layer sha256:f99bc9f2273f249174590ac76ba197ebf6420364ca457b06fe74a2290fd04c12 \n",
            "writing layer sha256:40f51e2438a3426ee1a2ae5596462e0c9117aa0be52510bf1428956050e63567 \n",
            "writing manifest \n",
            "success \u001b[?25h\n",
            "\n",
            "Fehler: \u001b[?25ltransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gtransferring model data \n",
            "creating model layer \n",
            "using already created layer sha256:f99bc9f2273f249174590ac76ba197ebf6420364ca457b06fe74a2290fd04c12 \n",
            "using already created layer sha256:40f51e2438a3426ee1a2ae5596462e0c9117aa0be52510bf1428956050e63567 \n",
            "writing manifest \n",
            "success \u001b[?25h\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Testdurchführung mit eigenen Prompts\n",
        "\n",
        "\n",
        "\n",
        "*  Eigenen Prompt eingeben um das Modell zu testen"
      ],
      "metadata": {
        "id": "UOP6-WkblpVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Benutzeraufforderung für den gesamten Prompt\n",
        "prompt = input(\"Bitte geben Sie Ihren Prompt ein: \")\n",
        "\n",
        "# Ausgabe des Prompts zur Überprüfung\n",
        "print(\"Ihr eingegebener Prompt lautet:\")\n",
        "print(prompt)\n",
        "\n",
        "url = 'http://localhost:11434/api/chat'\n",
        "payload = {\n",
        "    \"model\": \"ft_mistral\",\n",
        "    \"temperature\": 0.6,\n",
        "    \"stream\": False,\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"Du bist ein hilfreicher KI-Assistent!\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload)\n",
        "message_str = response.content.decode('utf-8')\n",
        "message_dict = json.loads(message_str)\n",
        "print(message_dict['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "_cMZMu3jfghn",
        "outputId": "2cf7ed77-c22c-4bc2-c9e3-6df48354b23d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7437c37723b0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Benutzeraufforderung für den gesamten Prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bitte geben Sie Ihren Prompt ein: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Ausgabe des Prompts zur Überprüfung\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ihr eingegebener Prompt lautet:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}